{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do cérebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar memória de conversa postgres\n",
    "# TODO implementar memória da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "\n",
    "class PrefrontalCortex(BaseModel):\n",
    "    expected_action: str = Field(..., description=\"Ação esperada para a entrada do humano\")\n",
    "    behavior_planner: str = Field(..., description=\"Informação necessária para o planejador de comportamento\")\n",
    "    decision_maker: str = Field(..., description=\"Informação necessária para o tomador de decisão\")\n",
    "    social_behavior_modulator: str = Field(..., description=\"Informação necessária para o modulador de comportamento social\")\n",
    "    complex_thought_planner: str = Field(..., description=\"Informação necessária para o planejador de pensamento complexo\")\n",
    "    personality_expression_planner: str = Field(..., description=\"Informação necessária para o planejador de expressão de personalidade\")\n",
    "\n",
    "parser_cortex = PydanticOutputParser(pydantic_object=PrefrontalCortex)\n",
    "\n",
    "template_prefrontal_cortex = \"\"\"\n",
    "Identificar a ação esperada para a entrada do humano: {input}\n",
    "O Prefrontal Cortex deve raciocinar sobre quais ações devem ser tomadas e como essas \n",
    "ações serão distribuídas entre os agentes. A tarefa envolve criar um plano estratégico \n",
    "que define claramente como cada agente contribuirá para o objetivo global.\n",
    "\n",
    "A saída esperada é um plano estratégico para distribuir as tarefas entre os \n",
    "agentes:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def clean_json(response):\n",
    "    # Removendo as marcações extras como ```json e \\n\n",
    "    clean_content = response.content.strip('```json\\n').strip('```')\n",
    "    \n",
    "    # Transformando em um dicionário\n",
    "    result_dict = json.loads(clean_content)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Creating the first analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "def prefrontal_cortex_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_prefrontal_cortex,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_cortex.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "    \n",
    "    state[\"behavior_planner\"] = result_dict[\"behavior_planner\"]\n",
    "    state[\"decision_maker\"] = result_dict[\"decision_maker\"]\n",
    "    state[\"social_behavior_modulator\"] = result_dict[\"social_behavior_modulator\"]\n",
    "    state[\"complex_thought_planner\"] = result_dict[\"complex_thought_planner\"]\n",
    "    state[\"personality_expression_planner\"] = result_dict[\"personality_expression_planner\"]\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "# Creating the second analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_behavior_planner = \"\"\"\n",
    "Interaction: {input}\n",
    "Expected action: {expected_action}\n",
    "\n",
    "You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "strategic execution of behaviors to meet the system’s goals.\n",
    "\n",
    "Your output must be in following format: \n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class BehaviorPlanner(BaseModel):\n",
    "    actual_behavior: str = Field(..., description=\"Comportamento atual\")\n",
    "    alternative_behavior: str = Field(..., description=\"Comportamento alternativo\")\n",
    "    control_mechanisms: str = Field(..., description=\"Mecanismo de controle e monitoramento\")\n",
    "    contingency_plans: str = Field(..., description=\"Planos de contingência\")\n",
    "\n",
    "parser_behavior_planner = PydanticOutputParser(pydantic_object=BehaviorPlanner)\n",
    "\n",
    "def behavior_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_behavior_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_behavior_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"behavior_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"actual_behavior\"] = result_dict[\"actual_behavior\"]\n",
    "    state[\"alternative_behavior\"] = result_dict[\"alternative_behavior\"]\n",
    "    state[\"control_mechanisms\"] = result_dict[\"control_mechanisms\"]\n",
    "    state[\"contingency_plans\"] = result_dict[\"contingency_plans\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# Creating the third analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_decision_maker = \"\"\"\n",
    "Interaction: {input}\n",
    "Expected action: {expected_action}\n",
    "\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the system’s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class DecisionMaker(BaseModel):\n",
    "    available_decisions: str = Field(..., description=\"Decisões disponíveis para o Brainiac\")\n",
    "    implications: str = Field(..., description=\"Implicações das decisões disponíveis\")\n",
    "    optimal_decision: str = Field(..., description=\"Decisão ótima para o Brainiac\")\n",
    "    decision_strategy: str = Field(..., description=\"Estratégia de decisão do Brainiac\")\n",
    "    decision_consistency: str = Field(..., description=\"Mecanismos de consistência e autenticidade nas decisões do Brainiac\")\n",
    "\n",
    "parser_decision_maker = PydanticOutputParser(pydantic_object=DecisionMaker)\n",
    "\n",
    "def decision_maker_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_decision_maker,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_decision_maker.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"decision_maker\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"available_decisions\"] = result_dict[\"available_decisions\"]\n",
    "    state[\"implications\"] = result_dict[\"implications\"]\n",
    "    state[\"optimal_decision\"] = result_dict[\"optimal_decision\"]\n",
    "    state[\"decision_strategy\"] = result_dict[\"decision_strategy\"]\n",
    "    state[\"decision_consistency\"] = result_dict[\"decision_consistency\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# Creating the fourth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_social_behavior_modulator = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the system’s responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class SocialBehaviorModulator(BaseModel):\n",
    "    social_behavior: str = Field(..., description=\"Comportamento social do Brainiac\")\n",
    "    guidelines: str = Field(..., description=\"Diretrizes para modulação do comportamento social\")\n",
    "    examples: str = Field(..., description=\"Exemplos de modulação do comportamento social\")\n",
    "    estrategy: str = Field(..., description=\"Estratégia de modulação do comportamento social\")\n",
    "    consistency: str = Field(..., description=\"Mecanismos de consistência e autenticidade na modulação do comportamento social\")\n",
    "\n",
    "parser_social_behavior_modulator = PydanticOutputParser(pydantic_object=SocialBehaviorModulator)\n",
    "\n",
    "def social_behavior_modulator_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_social_behavior_modulator,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_social_behavior_modulator.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"social_behavior_modulator\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"social_behavior\"] = result_dict[\"social_behavior\"]\n",
    "    state[\"guidelines\"] = result_dict[\"guidelines\"]\n",
    "    state[\"examples\"] = result_dict[\"examples\"]\n",
    "    state[\"estrategy\"] = result_dict[\"estrategy\"]\n",
    "    state[\"consistency\"] = result_dict[\"consistency\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# Creating the fifth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_complex_thought_planner = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the system’s objectives. \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class ComplexThoughtPlanner(BaseModel):\n",
    "    detailed_analysis: str = Field(..., description=\"Análise detalhada do problema\")\n",
    "    standard_relations: str = Field(..., description=\"Relações padrão entre os elementos\")\n",
    "    insights: str = Field(..., description=\"Insights profundos e soluções inovadoras\")\n",
    "    implications_scenarios: str = Field(..., description=\"Implicações de diferentes opções e cenários\")\n",
    "    comprehensive_understanding: str = Field(..., description=\"Compreensão abrangente do problema\")\n",
    "\n",
    "parser_complex_thought_planner = PydanticOutputParser(pydantic_object=ComplexThoughtPlanner)\n",
    "\n",
    "def complex_thought_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_complex_thought_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_complex_thought_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"complex_thought_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"detailed_analysis\"] = result_dict[\"detailed_analysis\"]\n",
    "    state[\"standard_relations\"] = result_dict[\"standard_relations\"]\n",
    "    state[\"insights\"] = result_dict[\"insights\"]\n",
    "    state[\"implications_scenarios\"] = result_dict[\"implications_scenarios\"]\n",
    "    state[\"comprehensive_understanding\"] = result_dict[\"comprehensive_understanding\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# Creating the sixth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_personality_expression_planner = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction.  \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class PersonalityExpressionPlanner(BaseModel):\n",
    "    personality: str = Field(..., description=\"Personalidade do Brainiac\")\n",
    "    guidelines: str = Field(..., description=\"Diretrizes para expressão da personalidade\")\n",
    "    examples: str = Field(..., description=\"Exemplos de expressão da personalidade\")\n",
    "    estrategy: str = Field(..., description=\"Estratégia de expressão da personalidade\")\n",
    "    consistency: str = Field(..., description=\"Mecanismos de consistência e autenticidade na expressão da personalidade\")\n",
    "\n",
    "parser_personality_expression_planner = PydanticOutputParser(pydantic_object=PersonalityExpressionPlanner)\n",
    "\n",
    "def personality_expression_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_personality_expression_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_personality_expression_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"personality_expression_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"personality\"] = result_dict[\"personality\"]\n",
    "    state[\"guidelines_personality\"] = result_dict[\"guidelines\"]\n",
    "    state[\"examples\"] = result_dict[\"examples\"]\n",
    "    state[\"estrategy\"] = result_dict[\"estrategy\"]\n",
    "    state[\"consistency\"] = result_dict[\"consistency\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "# Creating the seventh analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_cortex_out = \"\"\"\n",
    "Interaction: {input}\n",
    "\n",
    "The Prefrontal Cortex has analyzed the input and distributed the tasks among the agents.\n",
    "Here are the results:\n",
    "\n",
    "Behavior Planner:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import Annotated, TypedDict\n",
    "#from agents import analyze_question, answer_code_question, answer_generic_question\n",
    "\n",
    "#You can precise the format here which could be helpfull for multimodal graphs\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    expected_action: str\n",
    "    behavior_planner: str\n",
    "    decision_maker: str\n",
    "    social_behavior_modulator: str\n",
    "    complex_thought_planner: str\n",
    "    personality_expression_planner: str\n",
    "    actual_behavior: str\n",
    "    alternative_behavior: str\n",
    "    control_mechanisms: str\n",
    "    contingency_plans: str\n",
    "    available_decisions: str\n",
    "    implications: str\n",
    "    optimal_decision: str\n",
    "    decision_strategy: str\n",
    "    decision_consistency: str\n",
    "    social_behavior: str\n",
    "    guidelines: str\n",
    "    examples: str\n",
    "    estrategy: str\n",
    "    consistency: str\n",
    "    detailed_analysis: str\n",
    "    standard_relations: str\n",
    "    insights: str\n",
    "    implications_scenarios: str\n",
    "    comprehensive_understanding: str\n",
    "    personality: str\n",
    "    guidelines_personality: str\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#Here is a simple 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"prefrontal_cortex_agent\", prefrontal_cortex_agent)\n",
    "workflow.add_node(\"behavior_planner_agent\", behavior_planner_agent)\n",
    "workflow.add_node(\"decision_maker_agent\", decision_maker_agent)\n",
    "workflow.add_node(\"social_behavior_modulator_agent\", social_behavior_modulator_agent)\n",
    "workflow.add_node(\"complex_thought_planner_agent\", complex_thought_planner_agent)\n",
    "workflow.add_node(\"personality_expression_planner_agent\", personality_expression_planner_agent)\n",
    "#workflow.add_node(\"generic_agent\", answer_generic_question)\n",
    "\n",
    "#workflow.add_conditional_edges(\n",
    "#    \"analyze\",\n",
    "#    lambda x: x[\"decision\"],\n",
    "#    {\n",
    "#        \"code\": \"code_agent\",\n",
    "#        \"general\": \"generic_agent\"\n",
    "#    }\n",
    "#)\n",
    "\n",
    "workflow.set_entry_point(\"prefrontal_cortex_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"behavior_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"decision_maker_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"social_behavior_modulator_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"complex_thought_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"personality_expression_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_out_agent\", END)\n",
    "#workflow.add_edge(\"generic_agent\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prefrontal_cortex_agent': {'input': [HumanMessage(content='Oi?', additional_kwargs={}, response_metadata={})], 'behavior_planner': 'Identificar como o agente deve se comportar em resposta ao cumprimento, considerando um tom amigável e acolhedor.', 'decision_maker': 'Avaliar a melhor forma de engajar o humano na conversa, levando em conta possíveis tópicos de interesse.', 'social_behavior_modulator': 'Regular a intensidade da resposta para que seja percebida como positiva e envolvente, promovendo um ambiente de diálogo.', 'complex_thought_planner': 'Desenvolver um plano para possíveis próximas interações, considerando perguntas ou tópicos que possam ser abordados com o humano.', 'personality_expression_planner': 'Definir a personalidade que será expressa na resposta, garantindo que ela reflita características como simpatia e abertura.'}}\n",
      "----\n",
      "content='```json\\n{\\n  \"actual_behavior\": \"Responder ao cumprimento com um sorriso e um tom amigável, dizendo \\'Olá! Como você está?\\'\",\\n  \"alternative_behavior\": \"Acenar com a mão e fazer um gesto amigável, sem usar palavras, mas mantendo um sorriso acolhedor.\",\\n  \"control_mechanisms\": \"Monitorar a resposta da outra pessoa e ajustar o tom e a linguagem corporal conforme necessário para garantir uma interação positiva.\",\\n  \"contingency_plans\": \"Se a outra pessoa não responder ou parecer desconfortável, mudar para um tom mais neutro e oferecer um espaço para que ela possa se sentir mais à vontade.\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 356, 'total_tokens': 492, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None} id='run-0903a5df-7875-4221-9dbe-95fb14929631-0' usage_metadata={'input_tokens': 356, 'output_tokens': 136, 'total_tokens': 492}\n",
      "{'behavior_planner_agent': {'input': [HumanMessage(content='Oi?', additional_kwargs={}, response_metadata={})], 'behavior_planner': 'Identificar como o agente deve se comportar em resposta ao cumprimento, considerando um tom amigável e acolhedor.', 'decision_maker': 'Avaliar a melhor forma de engajar o humano na conversa, levando em conta possíveis tópicos de interesse.', 'social_behavior_modulator': 'Regular a intensidade da resposta para que seja percebida como positiva e envolvente, promovendo um ambiente de diálogo.', 'complex_thought_planner': 'Desenvolver um plano para possíveis próximas interações, considerando perguntas ou tópicos que possam ser abordados com o humano.', 'personality_expression_planner': 'Definir a personalidade que será expressa na resposta, garantindo que ela reflita características como simpatia e abertura.', 'actual_behavior': \"Responder ao cumprimento com um sorriso e um tom amigável, dizendo 'Olá! Como você está?'\", 'alternative_behavior': 'Acenar com a mão e fazer um gesto amigável, sem usar palavras, mas mantendo um sorriso acolhedor.', 'control_mechanisms': 'Monitorar a resposta da outra pessoa e ajustar o tom e a linguagem corporal conforme necessário para garantir uma interação positiva.', 'contingency_plans': 'Se a outra pessoa não responder ou parecer desconfortável, mudar para um tom mais neutro e oferecer um espaço para que ela possa se sentir mais à vontade.'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"input\": [\n",
    "            HumanMessage(content=\"Oi?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Claro! Estou aqui para ajudar. Quais problemas você está enfrentando?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 207, 'total_tokens': 223, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f3bfdb1-bfe1-4e67-b6f9-fa7b5cda9bf8-0', usage_metadata={'input_tokens': 207, 'output_tokens': 16, 'total_tokens': 223})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Estou com alguns problemas, você pode me ajudar?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Estou com alguns problemas, você pode me ajudar?\")]},\n",
    "    {\"recursion_limit\": 5},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Estou com alguns problemas, você pode me ajudar?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Claro! Estou aqui para ajudar. Quais problemas você está enfrentando?\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Estou com alguns problemas, você pode me ajudar?\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
