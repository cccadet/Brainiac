{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do c√©rebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar mem√≥ria de conversa postgres\n",
    "# TODO implementar mem√≥ria da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "\n",
    "class PrefrontalCortex(BaseModel):\n",
    "    expected_action: str = Field(..., description=\"A√ß√£o esperada para a entrada do humano\")\n",
    "    behavior_planner: str = Field(..., description=\"Informa√ß√£o necess√°ria para o planejador de comportamento\")\n",
    "    decision_maker: str = Field(..., description=\"Informa√ß√£o necess√°ria para o tomador de decis√£o\")\n",
    "    social_behavior_modulator: str = Field(..., description=\"Informa√ß√£o necess√°ria para o modulador de comportamento social\")\n",
    "    complex_thought_planner: str = Field(..., description=\"Informa√ß√£o necess√°ria para o planejador de pensamento complexo\")\n",
    "    personality_expression_planner: str = Field(..., description=\"Informa√ß√£o necess√°ria para o planejador de express√£o de personalidade\")\n",
    "\n",
    "parser_cortex = PydanticOutputParser(pydantic_object=PrefrontalCortex)\n",
    "\n",
    "template_prefrontal_cortex = \"\"\"\n",
    "Identificar a a√ß√£o esperada para a entrada do humano: {input}\n",
    "O Prefrontal Cortex deve raciocinar sobre quais a√ß√µes devem ser tomadas e como essas \n",
    "a√ß√µes ser√£o distribu√≠das entre os agentes. A tarefa envolve criar um plano estrat√©gico \n",
    "que define claramente como cada agente contribuir√° para o objetivo global.\n",
    "\n",
    "A sa√≠da esperada √© um plano estrat√©gico para distribuir as tarefas entre os \n",
    "agentes:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def clean_json(response):\n",
    "    # Removendo as marca√ß√µes extras como ```json e \\n\n",
    "    clean_content = response.content.strip('```json\\n').strip('```')\n",
    "    \n",
    "    # Transformando em um dicion√°rio\n",
    "    result_dict = json.loads(clean_content)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Creating the first analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "def prefrontal_cortex_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_prefrontal_cortex,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_cortex.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "    \n",
    "    state[\"behavior_planner\"] = result_dict[\"behavior_planner\"]\n",
    "    state[\"decision_maker\"] = result_dict[\"decision_maker\"]\n",
    "    state[\"social_behavior_modulator\"] = result_dict[\"social_behavior_modulator\"]\n",
    "    state[\"complex_thought_planner\"] = result_dict[\"complex_thought_planner\"]\n",
    "    state[\"personality_expression_planner\"] = result_dict[\"personality_expression_planner\"]\n",
    "\n",
    "\n",
    "    return {\"behavior_planner\": state[\"behavior_planner\"], \"decision_maker\": state[\"decision_maker\"], \"social_behavior_modulator\": state[\"social_behavior_modulator\"], \"complex_thought_planner\": state[\"complex_thought_planner\"], \"personality_expression_planner\": state[\"personality_expression_planner\"]}\n",
    "\n",
    "\n",
    "\n",
    "# Creating the second analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_behavior_planner = \"\"\"\n",
    "Interaction: {input}\n",
    "Expected action: {expected_action}\n",
    "\n",
    "You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "strategic execution of behaviors to meet the system‚Äôs goals.\n",
    "\n",
    "Your output must be in following format: \n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class BehaviorPlanner(BaseModel):\n",
    "    actual_behavior: str = Field(..., description=\"Comportamento atual\")\n",
    "    alternative_behavior: str = Field(..., description=\"Comportamento alternativo\")\n",
    "    control_mechanisms: str = Field(..., description=\"Mecanismo de controle e monitoramento\")\n",
    "    contingency_plans: str = Field(..., description=\"Planos de conting√™ncia\")\n",
    "\n",
    "parser_behavior_planner = PydanticOutputParser(pydantic_object=BehaviorPlanner)\n",
    "\n",
    "def behavior_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_behavior_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_behavior_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"behavior_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"actual_behavior\"] = result_dict[\"actual_behavior\"]\n",
    "    state[\"alternative_behavior\"] = result_dict[\"alternative_behavior\"]\n",
    "    state[\"control_mechanisms\"] = result_dict[\"control_mechanisms\"]\n",
    "    state[\"contingency_plans\"] = result_dict[\"contingency_plans\"]\n",
    "\n",
    "    return {\"actual_behavior\": state[\"actual_behavior\"], \"alternative_behavior\": state[\"alternative_behavior\"], \"control_mechanisms\": state[\"control_mechanisms\"], \"contingency_plans\": state[\"contingency_plans\"]}\n",
    "\n",
    "\n",
    "# Creating the third analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_decision_maker = \"\"\"\n",
    "Interaction: {input}\n",
    "Expected action: {expected_action}\n",
    "\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the system‚Äôs goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class DecisionMaker(BaseModel):\n",
    "    available_decisions: str = Field(..., description=\"Decis√µes dispon√≠veis para o Brainiac\")\n",
    "    implications: str = Field(..., description=\"Implica√ß√µes das decis√µes dispon√≠veis\")\n",
    "    optimal_decision: str = Field(..., description=\"Decis√£o √≥tima para o Brainiac\")\n",
    "    decision_strategy: str = Field(..., description=\"Estrat√©gia de decis√£o do Brainiac\")\n",
    "    decision_consistency: str = Field(..., description=\"Mecanismos de consist√™ncia e autenticidade nas decis√µes do Brainiac\")\n",
    "\n",
    "parser_decision_maker = PydanticOutputParser(pydantic_object=DecisionMaker)\n",
    "\n",
    "def decision_maker_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_decision_maker,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_decision_maker.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"decision_maker\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"available_decisions\"] = result_dict[\"available_decisions\"]\n",
    "    state[\"implications\"] = result_dict[\"implications\"]\n",
    "    state[\"optimal_decision\"] = result_dict[\"optimal_decision\"]\n",
    "    state[\"decision_strategy\"] = result_dict[\"decision_strategy\"]\n",
    "    state[\"decision_consistency\"] = result_dict[\"decision_consistency\"]\n",
    "\n",
    "    return {\"available_decisions\": state[\"available_decisions\"], \"implications\": state[\"implications\"], \"optimal_decision\": state[\"optimal_decision\"], \"decision_strategy\": state[\"decision_strategy\"], \"decision_consistency\": state[\"decision_consistency\"]}\n",
    "\n",
    "\n",
    "# Creating the fourth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_social_behavior_modulator = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the system‚Äôs responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class SocialBehaviorModulator(BaseModel):\n",
    "    social_behavior: str = Field(..., description=\"Comportamento social do Brainiac\")\n",
    "    guidelines: str = Field(..., description=\"Diretrizes para modula√ß√£o do comportamento social\")\n",
    "    examples_modulator: str = Field(..., description=\"Exemplos de modula√ß√£o do comportamento social\")\n",
    "    social_estrategy: str = Field(..., description=\"Estrat√©gia de modula√ß√£o do comportamento social\")\n",
    "    social_consistency: str = Field(..., description=\"Mecanismos de consist√™ncia e autenticidade na modula√ß√£o do comportamento social\")\n",
    "\n",
    "parser_social_behavior_modulator = PydanticOutputParser(pydantic_object=SocialBehaviorModulator)\n",
    "\n",
    "def social_behavior_modulator_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_social_behavior_modulator,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_social_behavior_modulator.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"social_behavior_modulator\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"social_behavior\"] = result_dict[\"social_behavior\"]\n",
    "    state[\"guidelines\"] = result_dict[\"guidelines\"]\n",
    "    state[\"examples_modulator\"] = result_dict[\"examples_modulator\"]\n",
    "    state[\"social_estrategy\"] = result_dict[\"social_estrategy\"]\n",
    "    state[\"social_consistency\"] = result_dict[\"social_consistency\"]\n",
    "\n",
    "    return {\"social_behavior\": state[\"social_behavior\"], \"guidelines\": state[\"guidelines\"], \"examples_modulator\": state[\"examples_modulator\"], \"social_estrategy\": state[\"social_estrategy\"], \"social_consistency\": state[\"social_consistency\"]}\n",
    "\n",
    "\n",
    "# Creating the fifth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_complex_thought_planner = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the system‚Äôs objectives. \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class ComplexThoughtPlanner(BaseModel):\n",
    "    detailed_analysis: str = Field(..., description=\"An√°lise detalhada do problema\")\n",
    "    standard_relations: str = Field(..., description=\"Rela√ß√µes padr√£o entre os elementos\")\n",
    "    insights: str = Field(..., description=\"Insights profundos e solu√ß√µes inovadoras\")\n",
    "    implications_scenarios: str = Field(..., description=\"Implica√ß√µes de diferentes op√ß√µes e cen√°rios\")\n",
    "    comprehensive_understanding: str = Field(..., description=\"Compreens√£o abrangente do problema\")\n",
    "\n",
    "parser_complex_thought_planner = PydanticOutputParser(pydantic_object=ComplexThoughtPlanner)\n",
    "\n",
    "def complex_thought_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_complex_thought_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_complex_thought_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"complex_thought_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"detailed_analysis\"] = result_dict[\"detailed_analysis\"]\n",
    "    state[\"standard_relations\"] = result_dict[\"standard_relations\"]\n",
    "    state[\"insights\"] = result_dict[\"insights\"]\n",
    "    state[\"implications_scenarios\"] = result_dict[\"implications_scenarios\"]\n",
    "    state[\"comprehensive_understanding\"] = result_dict[\"comprehensive_understanding\"]\n",
    "\n",
    "    return {\"detailed_analysis\": state[\"detailed_analysis\"], \"standard_relations\": state[\"standard_relations\"], \"insights\": state[\"insights\"], \"implications_scenarios\": state[\"implications_scenarios\"], \"comprehensive_understanding\": state[\"comprehensive_understanding\"]}\n",
    "\n",
    "\n",
    "# Creating the sixth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_personality_expression_planner = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction.  \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class PersonalityExpressionPlanner(BaseModel):\n",
    "    personality: str = Field(..., description=\"Personalidade do Brainiac\")\n",
    "    guidelines: str = Field(..., description=\"Diretrizes para express√£o da personalidade\")\n",
    "    examples_personality: str = Field(..., description=\"Exemplos de express√£o da personalidade\")\n",
    "    personality_estrategy: str = Field(..., description=\"Estrat√©gia de express√£o da personalidade\")\n",
    "    personality_consistency: str = Field(..., description=\"Mecanismos de consist√™ncia e autenticidade na express√£o da personalidade\")\n",
    "\n",
    "parser_personality_expression_planner = PydanticOutputParser(pydantic_object=PersonalityExpressionPlanner)\n",
    "\n",
    "def personality_expression_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_personality_expression_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_personality_expression_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"personality_expression_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"personality\"] = result_dict[\"personality\"]\n",
    "    state[\"guidelines_personality\"] = result_dict[\"guidelines\"]\n",
    "    state[\"examples_personality\"] = result_dict[\"examples_personality\"]\n",
    "    state[\"personality_estrategy\"] = result_dict[\"personality_estrategy\"]\n",
    "    state[\"personality_consistency\"] = result_dict[\"personality_consistency\"]\n",
    "\n",
    "    return {\"personality\": state[\"personality\"], \"guidelines_personality\": state[\"guidelines_personality\"], \"examples_personality\": state[\"examples_personality\"], \"personality_estrategy\": state[\"personality_estrategy\"], \"personality_consistency\": state[\"personality_consistency\"]}\n",
    "\n",
    "# Creating the seventh analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_cortex_out = \"\"\"\n",
    "Interaction: {input}\n",
    "\n",
    "The Prefrontal Cortex has analyzed the input and distributed the tasks among the agents.\n",
    "Here are the results:\n",
    "\n",
    "Behavior Planner: \n",
    "- Actual Behavior: {actual_behavior}\n",
    "- Alternative Behavior: {alternative_behavior}\n",
    "- Control Mechanisms: {control_mechanisms}\n",
    "- Contingency Plans: {contingency_plans}\n",
    "\n",
    "Decision Maker:\n",
    "- Available Decisions: {available_decisions}\n",
    "- Implications: {implications}\n",
    "- Optimal Decision: {optimal_decision}\n",
    "- Decision Strategy: {decision_strategy}\n",
    "- Decision Consistency: {decision_consistency}\n",
    "\n",
    "Social Behavior Modulator:\n",
    "- Social Behavior: {social_behavior}\n",
    "- Guidelines: {guidelines}\n",
    "- Modulator Examples: {examples_modulator}\n",
    "- Social Estrategy: {social_estrategy}\n",
    "- Social Consistency: {social_consistency}\n",
    "\n",
    "Complex Thought Planner:\n",
    "- Detailed Analysis: {detailed_analysis}\n",
    "- Standard Relations: {standard_relations}\n",
    "- Insights: {insights}\n",
    "- Implications Scenarios: {implications_scenarios}\n",
    "- Comprehensive Understanding: {comprehensive_understanding}\n",
    "\n",
    "Personality Expression Planner:\n",
    "- Personality: {personality}\n",
    "- Guidelines: {guidelines_personality}\n",
    "- Personality Examples: {examples_personality}\n",
    "- Personality Estrategy: {personality_estrategy}\n",
    "- Personality Consistency: {personality_consistency}\n",
    "\n",
    "Based on this analysis, answer the interaction.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cortex_out_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_cortex_out,\n",
    "        input_variables=[\"input\"]\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\n",
    "        \"input\": state[\"input\"],\n",
    "        #\"expected_action\": state[\"expected_action\"],\n",
    "        \"actual_behavior\": state[\"actual_behavior\"],\n",
    "        \"alternative_behavior\": state[\"alternative_behavior\"],\n",
    "        \"control_mechanisms\": state[\"control_mechanisms\"],\n",
    "        \"contingency_plans\": state[\"contingency_plans\"],\n",
    "        \"available_decisions\": state[\"available_decisions\"],\n",
    "        \"implications\": state[\"implications\"],\n",
    "        \"optimal_decision\": state[\"optimal_decision\"],\n",
    "        \"decision_strategy\": state[\"decision_strategy\"],\n",
    "        \"decision_consistency\": state[\"decision_consistency\"],\n",
    "        \"social_behavior\": state[\"social_behavior\"],\n",
    "        \"guidelines\": state[\"guidelines\"],\n",
    "        \"examples_modulator\": state[\"examples_modulator\"],\n",
    "        \"social_estrategy\": state[\"social_estrategy\"],\n",
    "        \"social_consistency\": state[\"social_consistency\"],\n",
    "        \"detailed_analysis\": state[\"detailed_analysis\"],\n",
    "        \"standard_relations\": state[\"standard_relations\"],\n",
    "        \"insights\": state[\"insights\"],\n",
    "        \"implications_scenarios\": state[\"implications_scenarios\"],\n",
    "        \"comprehensive_understanding\": state[\"comprehensive_understanding\"],\n",
    "        \"personality\": state[\"personality\"],\n",
    "        \"guidelines_personality\": state[\"guidelines_personality\"],\n",
    "        \"examples_personality\": state[\"examples_personality\"],\n",
    "        \"personality_estrategy\": state[\"personality_estrategy\"],\n",
    "        \"personality_consistency\": state[\"personality_consistency\"]\n",
    "    })\n",
    "    state[\"output\"] = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import Annotated, TypedDict\n",
    "#from agents import analyze_question, answer_code_question, answer_generic_question\n",
    "\n",
    "#You can precise the format here which could be helpfull for multimodal graphs\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    behavior_planner: str\n",
    "    decision_maker: str\n",
    "    social_behavior_modulator: str\n",
    "    complex_thought_planner: str\n",
    "    personality_expression_planner: str\n",
    "    actual_behavior: str\n",
    "    alternative_behavior: str\n",
    "    control_mechanisms: str\n",
    "    contingency_plans: str\n",
    "    available_decisions: str\n",
    "    implications: str\n",
    "    optimal_decision: str\n",
    "    decision_strategy: str\n",
    "    decision_consistency: str\n",
    "    social_behavior: str\n",
    "    guidelines: str\n",
    "    examples_personality: str\n",
    "    examples_modulator: str\n",
    "    social_estrategy: str\n",
    "    social_consistency: str\n",
    "    personality_estrategy: str\n",
    "    personality_consistency: str\n",
    "    detailed_analysis: str\n",
    "    standard_relations: str\n",
    "    insights: str\n",
    "    implications_scenarios: str\n",
    "    comprehensive_understanding: str\n",
    "    personality: str\n",
    "    guidelines_personality: str\n",
    "\n",
    "\n",
    "#Here is a simple 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"prefrontal_cortex_agent\", prefrontal_cortex_agent)\n",
    "workflow.add_node(\"behavior_planner_agent\", behavior_planner_agent)\n",
    "workflow.add_node(\"decision_maker_agent\", decision_maker_agent)\n",
    "workflow.add_node(\"social_behavior_modulator_agent\", social_behavior_modulator_agent)\n",
    "workflow.add_node(\"complex_thought_planner_agent\", complex_thought_planner_agent)\n",
    "workflow.add_node(\"personality_expression_planner_agent\", personality_expression_planner_agent)\n",
    "workflow.add_node(\"prefrontal_cortex_out_agent\", cortex_out_agent)\n",
    "#workflow.add_node(\"generic_agent\", answer_generic_question)\n",
    "\n",
    "#workflow.add_conditional_edges(\n",
    "#    \"analyze\",\n",
    "#    lambda x: x[\"decision\"],\n",
    "#    {\n",
    "#        \"code\": \"code_agent\",\n",
    "#        \"general\": \"generic_agent\"\n",
    "#    }\n",
    "#)\n",
    "\n",
    "workflow.set_entry_point(\"prefrontal_cortex_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"behavior_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"decision_maker_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"social_behavior_modulator_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"complex_thought_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"personality_expression_planner_agent\")\n",
    "workflow.add_edge([\"behavior_planner_agent\",\"decision_maker_agent\", \"social_behavior_modulator_agent\", \"complex_thought_planner_agent\", \"personality_expression_planner_agent\"], \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"decision_maker_agent\", \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"social_behavior_modulator_agent\", \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"complex_thought_planner_agent\", \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"personality_expression_planner_agent\", \"prefrontal_cortex_out_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_out_agent\", END)\n",
    "#workflow.add_edge(\"generic_agent\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prefrontal_cortex_agent': {'behavior_planner': 'Desenvolver um plano para iniciar uma conversa, incluindo t√≥picos leves ou perguntas abertas para engajar o humano.', 'decision_maker': 'Avaliar o tom da intera√ß√£o e selecionar a resposta mais apropriada com base no contexto e na personalidade do agente.', 'social_behavior_modulator': 'Ajustar o n√≠vel de empatia e cordialidade na resposta, de acordo com as normas sociais de intera√ß√£o.', 'complex_thought_planner': 'Analisar poss√≠veis dire√ß√µes para a conversa e preparar respostas para diferentes cen√°rios que possam surgir a partir do cumprimento.', 'personality_expression_planner': 'Definir uma resposta que reflita uma personalidade amig√°vel e acess√≠vel, garantindo que a intera√ß√£o seja agrad√°vel.'}}\n",
      "----\n",
      "{'social_behavior_modulator_agent': {'social_behavior': 'Acolhedor e amig√°vel', 'guidelines': 'Manter um tom cordial e receptivo, utilizando uma linguagem simples e amig√°vel.', 'examples_modulator': \"Responder com um 'Oi! Como posso ajudar voc√™ hoje?' para mostrar interesse e abertura.\", 'social_estrategy': 'Utilizar cumprimentos e perguntas abertas para incentivar a intera√ß√£o e promover um ambiente confort√°vel.', 'social_consistency': 'Garantir que todas as respostas mantenham um tom positivo e respeitoso, refletindo uma abordagem amig√°vel em todas as intera√ß√µes.'}}\n",
      "----\n",
      "{'behavior_planner_agent': {'actual_behavior': \"Iniciar uma conversa com um simples 'Oi?'\", 'alternative_behavior': \"Fazer uma pergunta aberta sobre o dia ou interesses da pessoa, como 'Como foi seu dia?' ou 'O que voc√™ tem feito ultimamente?'\", 'control_mechanisms': 'Avaliar as respostas da pessoa para ajustar o tom da conversa, buscando manter um fluxo natural e envolvente.', 'contingency_plans': 'Se a pessoa n√£o responder ou parecer desinteressada, mudar para t√≥picos mais leves, como hobbies, filmes ou m√∫sica, ou fazer uma pausa e tentar novamente mais tarde.'}}\n",
      "----\n",
      "{'personality_expression_planner_agent': {'examples_personality': 'Ol√°! Como voc√™ est√°? Estou aqui para ajudar no que precisar! üòä', 'personality_estrategy': 'Utilizar emojis e express√µes amig√°veis para criar uma conex√£o mais pr√≥xima com o usu√°rio.', 'personality_consistency': 'Manter um tom positivo em todas as intera√ß√µes, assegurando que as respostas reflitam empatia e compreens√£o.', 'personality': 'Amig√°vel e acess√≠vel', 'guidelines_personality': 'Responder de forma calorosa e envolvente, utilizando uma linguagem simples e encorajadora.'}}\n",
      "----\n",
      "{'decision_maker_agent': {'available_decisions': 'Responder de forma amig√°vel e acolhedora ou ignorar a mensagem.', 'implications': 'Responder de forma amig√°vel pode encorajar mais intera√ß√µes, enquanto ignorar pode levar a mal-entendidos ou a uma intera√ß√£o negativa.', 'optimal_decision': 'Responder de forma amig√°vel e acolhedora.', 'decision_strategy': 'Analisar o tom da mensagem e optar por uma resposta que promova uma intera√ß√£o positiva, levando em conta a cordialidade.', 'decision_consistency': 'As decis√µes s√£o consistentes com a personalidade amig√°vel e acess√≠vel do agente, promovendo um ambiente positivo de intera√ß√£o.'}}\n",
      "----\n",
      "{'complex_thought_planner_agent': {'detailed_analysis': \"O cumprimento 'Oi?' pode ser interpretado de v√°rias maneiras, dependendo do tom, contexto e rela√ß√£o entre as partes envolvidas. √â uma sauda√ß√£o informal que geralmente indica curiosidade ou uma tentativa de iniciar uma conversa. Essa intera√ß√£o pode ser vista como um convite para troca de informa√ß√µes ou um sinal de que a outra parte est√° aberta para dialogar.\", 'standard_relations': \"A rela√ß√£o padr√£o entre o cumprimento e a resposta pode incluir um reconhecimento cordial e a continuidade da conversa. Respostas t√≠picas incluem 'Oi!' ou perguntas como 'Como voc√™ est√°?' que buscam aprofundar a intera√ß√£o. √â comum que o cumprimento seja seguido por um compartilhamento de novidades ou questionamentos.\", 'insights': \"Um insight interessante √© que o uso de 'Oi?' em vez de um cumprimento mais elaborado pode indicar uma abordagem mais casual ou at√© mesmo um estado de esp√≠rito descontra√≠do. Isso pode abrir espa√ßo para uma conversa mais leve, mas tamb√©m pode ser uma oportunidade para mergulhar em t√≥picos mais profundos, dependendo da dire√ß√£o que a conversa tomar.\", 'implications_scenarios': 'Dependendo da resposta ao cumprimento, diferentes cen√°rios podem surgir. Se a resposta for calorosa, pode levar a uma conversa mais longa e envolvente. Se a resposta for breve ou desinteressada, pode indicar que a outra parte n√£o est√° disposta a se engajar, o que pode resultar em uma intera√ß√£o mais superficial. Al√©m disso, se a resposta for uma pergunta, isso pode redirecionar a conversa para um novo tema.', 'comprehensive_understanding': \"A compreens√£o abrangente da intera√ß√£o come√ßa com o reconhecimento de que 'Oi?' √© mais do que uma simples sauda√ß√£o; √© um ponto de partida que define o tom da conversa. A forma como a outra parte responde pode variar amplamente e deve ser considerada no contexto mais amplo da rela√ß√£o entre as partes, bem como do ambiente social ou cultural em que a intera√ß√£o ocorre.\"}}\n",
      "----\n",
      "{'prefrontal_cortex_out_agent': {'input': [HumanMessage(content='Oi?', additional_kwargs={}, response_metadata={})], 'output': AIMessage(content='Oi! Como voc√™ est√°? Estou aqui para ajudar no que precisar! üòä', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 923, 'total_tokens': 938, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}, id='run-9435f333-419e-4679-8de1-2ce1755a9179-0', usage_metadata={'input_tokens': 923, 'output_tokens': 15, 'total_tokens': 938}), 'behavior_planner': 'Desenvolver um plano para iniciar uma conversa, incluindo t√≥picos leves ou perguntas abertas para engajar o humano.', 'decision_maker': 'Avaliar o tom da intera√ß√£o e selecionar a resposta mais apropriada com base no contexto e na personalidade do agente.', 'social_behavior_modulator': 'Ajustar o n√≠vel de empatia e cordialidade na resposta, de acordo com as normas sociais de intera√ß√£o.', 'complex_thought_planner': 'Analisar poss√≠veis dire√ß√µes para a conversa e preparar respostas para diferentes cen√°rios que possam surgir a partir do cumprimento.', 'personality_expression_planner': 'Definir uma resposta que reflita uma personalidade amig√°vel e acess√≠vel, garantindo que a intera√ß√£o seja agrad√°vel.', 'actual_behavior': \"Iniciar uma conversa com um simples 'Oi?'\", 'alternative_behavior': \"Fazer uma pergunta aberta sobre o dia ou interesses da pessoa, como 'Como foi seu dia?' ou 'O que voc√™ tem feito ultimamente?'\", 'control_mechanisms': 'Avaliar as respostas da pessoa para ajustar o tom da conversa, buscando manter um fluxo natural e envolvente.', 'contingency_plans': 'Se a pessoa n√£o responder ou parecer desinteressada, mudar para t√≥picos mais leves, como hobbies, filmes ou m√∫sica, ou fazer uma pausa e tentar novamente mais tarde.', 'available_decisions': 'Responder de forma amig√°vel e acolhedora ou ignorar a mensagem.', 'implications': 'Responder de forma amig√°vel pode encorajar mais intera√ß√µes, enquanto ignorar pode levar a mal-entendidos ou a uma intera√ß√£o negativa.', 'optimal_decision': 'Responder de forma amig√°vel e acolhedora.', 'decision_strategy': 'Analisar o tom da mensagem e optar por uma resposta que promova uma intera√ß√£o positiva, levando em conta a cordialidade.', 'decision_consistency': 'As decis√µes s√£o consistentes com a personalidade amig√°vel e acess√≠vel do agente, promovendo um ambiente positivo de intera√ß√£o.', 'social_behavior': 'Acolhedor e amig√°vel', 'guidelines': 'Manter um tom cordial e receptivo, utilizando uma linguagem simples e amig√°vel.', 'examples_personality': 'Ol√°! Como voc√™ est√°? Estou aqui para ajudar no que precisar! üòä', 'examples_modulator': \"Responder com um 'Oi! Como posso ajudar voc√™ hoje?' para mostrar interesse e abertura.\", 'social_estrategy': 'Utilizar cumprimentos e perguntas abertas para incentivar a intera√ß√£o e promover um ambiente confort√°vel.', 'social_consistency': 'Garantir que todas as respostas mantenham um tom positivo e respeitoso, refletindo uma abordagem amig√°vel em todas as intera√ß√µes.', 'personality_estrategy': 'Utilizar emojis e express√µes amig√°veis para criar uma conex√£o mais pr√≥xima com o usu√°rio.', 'personality_consistency': 'Manter um tom positivo em todas as intera√ß√µes, assegurando que as respostas reflitam empatia e compreens√£o.', 'detailed_analysis': \"O cumprimento 'Oi?' pode ser interpretado de v√°rias maneiras, dependendo do tom, contexto e rela√ß√£o entre as partes envolvidas. √â uma sauda√ß√£o informal que geralmente indica curiosidade ou uma tentativa de iniciar uma conversa. Essa intera√ß√£o pode ser vista como um convite para troca de informa√ß√µes ou um sinal de que a outra parte est√° aberta para dialogar.\", 'standard_relations': \"A rela√ß√£o padr√£o entre o cumprimento e a resposta pode incluir um reconhecimento cordial e a continuidade da conversa. Respostas t√≠picas incluem 'Oi!' ou perguntas como 'Como voc√™ est√°?' que buscam aprofundar a intera√ß√£o. √â comum que o cumprimento seja seguido por um compartilhamento de novidades ou questionamentos.\", 'insights': \"Um insight interessante √© que o uso de 'Oi?' em vez de um cumprimento mais elaborado pode indicar uma abordagem mais casual ou at√© mesmo um estado de esp√≠rito descontra√≠do. Isso pode abrir espa√ßo para uma conversa mais leve, mas tamb√©m pode ser uma oportunidade para mergulhar em t√≥picos mais profundos, dependendo da dire√ß√£o que a conversa tomar.\", 'implications_scenarios': 'Dependendo da resposta ao cumprimento, diferentes cen√°rios podem surgir. Se a resposta for calorosa, pode levar a uma conversa mais longa e envolvente. Se a resposta for breve ou desinteressada, pode indicar que a outra parte n√£o est√° disposta a se engajar, o que pode resultar em uma intera√ß√£o mais superficial. Al√©m disso, se a resposta for uma pergunta, isso pode redirecionar a conversa para um novo tema.', 'comprehensive_understanding': \"A compreens√£o abrangente da intera√ß√£o come√ßa com o reconhecimento de que 'Oi?' √© mais do que uma simples sauda√ß√£o; √© um ponto de partida que define o tom da conversa. A forma como a outra parte responde pode variar amplamente e deve ser considerada no contexto mais amplo da rela√ß√£o entre as partes, bem como do ambiente social ou cultural em que a intera√ß√£o ocorre.\", 'personality': 'Amig√°vel e acess√≠vel', 'guidelines_personality': 'Responder de forma calorosa e envolvente, utilizando uma linguagem simples e encorajadora.'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"input\": [\n",
    "            HumanMessage(content=\"Oi?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Claro! Estou aqui para ajudar. Quais problemas voc√™ est√° enfrentando?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 207, 'total_tokens': 223, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f3bfdb1-bfe1-4e67-b6f9-fa7b5cda9bf8-0', usage_metadata={'input_tokens': 207, 'output_tokens': 16, 'total_tokens': 223})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Estou com alguns problemas, voc√™ pode me ajudar?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Estou com alguns problemas, voc√™ pode me ajudar?\")]},\n",
    "    {\"recursion_limit\": 5},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Estou com alguns problemas, voc√™ pode me ajudar?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Claro! Estou aqui para ajudar. Quais problemas voc√™ est√° enfrentando?\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Estou com alguns problemas, voc√™ pode me ajudar?\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
