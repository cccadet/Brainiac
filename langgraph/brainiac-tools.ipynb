{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do cérebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar memória de conversa postgres\n",
    "# TODO implementar memória da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "\n",
    "class PrefrontalCortex(BaseModel):\n",
    "    expected_action: str = Field(..., description=\"Ação esperada para a entrada do humano\")\n",
    "    behavior_planner: str = Field(..., description=\"Informação necessária para o planejador de comportamento\")\n",
    "    decision_maker: str = Field(..., description=\"Informação necessária para o tomador de decisão\")\n",
    "    social_behavior_modulator: str = Field(..., description=\"Informação necessária para o modulador de comportamento social\")\n",
    "    complex_thought_planner: str = Field(..., description=\"Informação necessária para o planejador de pensamento complexo\")\n",
    "    personality_expression_planner: str = Field(..., description=\"Informação necessária para o planejador de expressão de personalidade\")\n",
    "\n",
    "parser_cortex = PydanticOutputParser(pydantic_object=PrefrontalCortex)\n",
    "\n",
    "template_prefrontal_cortex = \"\"\"\n",
    "Identificar a ação esperada para a entrada do humano: {input}\n",
    "O Prefrontal Cortex deve raciocinar sobre quais ações devem ser tomadas e como essas \n",
    "ações serão distribuídas entre os agentes. A tarefa envolve criar um plano estratégico \n",
    "que define claramente como cada agente contribuirá para o objetivo global.\n",
    "\n",
    "A saída esperada é um plano estratégico para distribuir as tarefas entre os \n",
    "agentes:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def clean_json(response):\n",
    "    # Removendo as marcações extras como ```json e \\n\n",
    "    clean_content = response.content.strip('```json\\n').strip('```')\n",
    "    \n",
    "    # Transformando em um dicionário\n",
    "    result_dict = json.loads(clean_content)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Creating the first analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "def prefrontal_cortex_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_prefrontal_cortex,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_cortex.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "    \n",
    "    state[\"behavior_planner\"] = result_dict[\"behavior_planner\"]\n",
    "    state[\"decision_maker\"] = result_dict[\"decision_maker\"]\n",
    "    state[\"social_behavior_modulator\"] = result_dict[\"social_behavior_modulator\"]\n",
    "    state[\"complex_thought_planner\"] = result_dict[\"complex_thought_planner\"]\n",
    "    state[\"personality_expression_planner\"] = result_dict[\"personality_expression_planner\"]\n",
    "\n",
    "\n",
    "    return {\"behavior_planner\": state[\"behavior_planner\"], \"decision_maker\": state[\"decision_maker\"], \"social_behavior_modulator\": state[\"social_behavior_modulator\"], \"complex_thought_planner\": state[\"complex_thought_planner\"], \"personality_expression_planner\": state[\"personality_expression_planner\"]}\n",
    "\n",
    "\n",
    "\n",
    "# Creating the second analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_behavior_planner = \"\"\"\n",
    "Interaction: {input}\n",
    "Expected action: {expected_action}\n",
    "\n",
    "You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "strategic execution of behaviors to meet the system’s goals.\n",
    "\n",
    "Your output must be in following format: \n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class BehaviorPlanner(BaseModel):\n",
    "    actual_behavior: str = Field(..., description=\"Comportamento atual\")\n",
    "    alternative_behavior: str = Field(..., description=\"Comportamento alternativo\")\n",
    "    control_mechanisms: str = Field(..., description=\"Mecanismo de controle e monitoramento\")\n",
    "    contingency_plans: str = Field(..., description=\"Planos de contingência\")\n",
    "\n",
    "parser_behavior_planner = PydanticOutputParser(pydantic_object=BehaviorPlanner)\n",
    "\n",
    "def behavior_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_behavior_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_behavior_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"behavior_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"actual_behavior\"] = result_dict[\"actual_behavior\"]\n",
    "    state[\"alternative_behavior\"] = result_dict[\"alternative_behavior\"]\n",
    "    state[\"control_mechanisms\"] = result_dict[\"control_mechanisms\"]\n",
    "    state[\"contingency_plans\"] = result_dict[\"contingency_plans\"]\n",
    "\n",
    "    return {\"actual_behavior\": state[\"actual_behavior\"], \"alternative_behavior\": state[\"alternative_behavior\"], \"control_mechanisms\": state[\"control_mechanisms\"], \"contingency_plans\": state[\"contingency_plans\"]}\n",
    "\n",
    "\n",
    "# Creating the third analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_decision_maker = \"\"\"\n",
    "Interaction: {input}\n",
    "Expected action: {expected_action}\n",
    "\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the system’s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class DecisionMaker(BaseModel):\n",
    "    available_decisions: str = Field(..., description=\"Decisões disponíveis para o Brainiac\")\n",
    "    implications: str = Field(..., description=\"Implicações das decisões disponíveis\")\n",
    "    optimal_decision: str = Field(..., description=\"Decisão ótima para o Brainiac\")\n",
    "    decision_strategy: str = Field(..., description=\"Estratégia de decisão do Brainiac\")\n",
    "    decision_consistency: str = Field(..., description=\"Mecanismos de consistência e autenticidade nas decisões do Brainiac\")\n",
    "\n",
    "parser_decision_maker = PydanticOutputParser(pydantic_object=DecisionMaker)\n",
    "\n",
    "def decision_maker_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_decision_maker,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_decision_maker.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"decision_maker\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"available_decisions\"] = result_dict[\"available_decisions\"]\n",
    "    state[\"implications\"] = result_dict[\"implications\"]\n",
    "    state[\"optimal_decision\"] = result_dict[\"optimal_decision\"]\n",
    "    state[\"decision_strategy\"] = result_dict[\"decision_strategy\"]\n",
    "    state[\"decision_consistency\"] = result_dict[\"decision_consistency\"]\n",
    "\n",
    "    return {\"available_decisions\": state[\"available_decisions\"], \"implications\": state[\"implications\"], \"optimal_decision\": state[\"optimal_decision\"], \"decision_strategy\": state[\"decision_strategy\"], \"decision_consistency\": state[\"decision_consistency\"]}\n",
    "\n",
    "\n",
    "# Creating the fourth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_social_behavior_modulator = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the system’s responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class SocialBehaviorModulator(BaseModel):\n",
    "    social_behavior: str = Field(..., description=\"Comportamento social do Brainiac\")\n",
    "    guidelines: str = Field(..., description=\"Diretrizes para modulação do comportamento social\")\n",
    "    examples_modulator: str = Field(..., description=\"Exemplos de modulação do comportamento social\")\n",
    "    social_estrategy: str = Field(..., description=\"Estratégia de modulação do comportamento social\")\n",
    "    social_consistency: str = Field(..., description=\"Mecanismos de consistência e autenticidade na modulação do comportamento social\")\n",
    "\n",
    "parser_social_behavior_modulator = PydanticOutputParser(pydantic_object=SocialBehaviorModulator)\n",
    "\n",
    "def social_behavior_modulator_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_social_behavior_modulator,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_social_behavior_modulator.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"social_behavior_modulator\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"social_behavior\"] = result_dict[\"social_behavior\"]\n",
    "    state[\"guidelines\"] = result_dict[\"guidelines\"]\n",
    "    state[\"examples_modulator\"] = result_dict[\"examples_modulator\"]\n",
    "    state[\"social_estrategy\"] = result_dict[\"social_estrategy\"]\n",
    "    state[\"social_consistency\"] = result_dict[\"social_consistency\"]\n",
    "\n",
    "    return {\"social_behavior\": state[\"social_behavior\"], \"guidelines\": state[\"guidelines\"], \"examples_modulator\": state[\"examples_modulator\"], \"social_estrategy\": state[\"social_estrategy\"], \"social_consistency\": state[\"social_consistency\"]}\n",
    "\n",
    "\n",
    "# Creating the fifth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_complex_thought_planner = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the system’s objectives. \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class ComplexThoughtPlanner(BaseModel):\n",
    "    detailed_analysis: str = Field(..., description=\"Análise detalhada do problema\")\n",
    "    standard_relations: str = Field(..., description=\"Relações padrão entre os elementos\")\n",
    "    insights: str = Field(..., description=\"Insights profundos e soluções inovadoras\")\n",
    "    implications_scenarios: str = Field(..., description=\"Implicações de diferentes opções e cenários\")\n",
    "    comprehensive_understanding: str = Field(..., description=\"Compreensão abrangente do problema\")\n",
    "\n",
    "parser_complex_thought_planner = PydanticOutputParser(pydantic_object=ComplexThoughtPlanner)\n",
    "\n",
    "def complex_thought_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_complex_thought_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_complex_thought_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"complex_thought_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"detailed_analysis\"] = result_dict[\"detailed_analysis\"]\n",
    "    state[\"standard_relations\"] = result_dict[\"standard_relations\"]\n",
    "    state[\"insights\"] = result_dict[\"insights\"]\n",
    "    state[\"implications_scenarios\"] = result_dict[\"implications_scenarios\"]\n",
    "    state[\"comprehensive_understanding\"] = result_dict[\"comprehensive_understanding\"]\n",
    "\n",
    "    return {\"detailed_analysis\": state[\"detailed_analysis\"], \"standard_relations\": state[\"standard_relations\"], \"insights\": state[\"insights\"], \"implications_scenarios\": state[\"implications_scenarios\"], \"comprehensive_understanding\": state[\"comprehensive_understanding\"]}\n",
    "\n",
    "\n",
    "# Creating the sixth analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_personality_expression_planner = \"\"\"\n",
    "    Interaction: {input}\n",
    "    Expected action: {expected_action}\n",
    "\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction.  \n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "class PersonalityExpressionPlanner(BaseModel):\n",
    "    personality: str = Field(..., description=\"Personalidade do Brainiac\")\n",
    "    guidelines: str = Field(..., description=\"Diretrizes para expressão da personalidade\")\n",
    "    examples_personality: str = Field(..., description=\"Exemplos de expressão da personalidade\")\n",
    "    personality_estrategy: str = Field(..., description=\"Estratégia de expressão da personalidade\")\n",
    "    personality_consistency: str = Field(..., description=\"Mecanismos de consistência e autenticidade na expressão da personalidade\")\n",
    "\n",
    "parser_personality_expression_planner = PydanticOutputParser(pydantic_object=PersonalityExpressionPlanner)\n",
    "\n",
    "def personality_expression_planner_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_personality_expression_planner,\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": parser_personality_expression_planner.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\"input\": state[\"input\"], \"expected_action\": state[\"personality_expression_planner\"]})\n",
    "\n",
    "    result_dict = clean_json(response)\n",
    "\n",
    "    state[\"personality\"] = result_dict[\"personality\"]\n",
    "    state[\"guidelines_personality\"] = result_dict[\"guidelines\"]\n",
    "    state[\"examples_personality\"] = result_dict[\"examples_personality\"]\n",
    "    state[\"personality_estrategy\"] = result_dict[\"personality_estrategy\"]\n",
    "    state[\"personality_consistency\"] = result_dict[\"personality_consistency\"]\n",
    "\n",
    "    return {\"personality\": state[\"personality\"], \"guidelines_personality\": state[\"guidelines_personality\"], \"examples_personality\": state[\"examples_personality\"], \"personality_estrategy\": state[\"personality_estrategy\"], \"personality_consistency\": state[\"personality_consistency\"]}\n",
    "\n",
    "# Creating the seventh analysis agent to check the prompt structure\n",
    "# This print part helps you to trace the graph decisions\n",
    "template_cortex_out = \"\"\"\n",
    "Interaction: {input}\n",
    "\n",
    "The Prefrontal Cortex has analyzed the input and distributed the tasks among the agents.\n",
    "Here are the results:\n",
    "\n",
    "Behavior Planner: \n",
    "- Actual Behavior: {actual_behavior}\n",
    "- Alternative Behavior: {alternative_behavior}\n",
    "- Control Mechanisms: {control_mechanisms}\n",
    "- Contingency Plans: {contingency_plans}\n",
    "\n",
    "Decision Maker:\n",
    "- Available Decisions: {available_decisions}\n",
    "- Implications: {implications}\n",
    "- Optimal Decision: {optimal_decision}\n",
    "- Decision Strategy: {decision_strategy}\n",
    "- Decision Consistency: {decision_consistency}\n",
    "\n",
    "Social Behavior Modulator:\n",
    "- Social Behavior: {social_behavior}\n",
    "- Guidelines: {guidelines}\n",
    "- Modulator Examples: {examples_modulator}\n",
    "- Social Estrategy: {social_estrategy}\n",
    "- Social Consistency: {social_consistency}\n",
    "\n",
    "Complex Thought Planner:\n",
    "- Detailed Analysis: {detailed_analysis}\n",
    "- Standard Relations: {standard_relations}\n",
    "- Insights: {insights}\n",
    "- Implications Scenarios: {implications_scenarios}\n",
    "- Comprehensive Understanding: {comprehensive_understanding}\n",
    "\n",
    "Personality Expression Planner:\n",
    "- Personality: {personality}\n",
    "- Guidelines: {guidelines_personality}\n",
    "- Personality Examples: {examples_personality}\n",
    "- Personality Estrategy: {personality_estrategy}\n",
    "- Personality Consistency: {personality_consistency}\n",
    "\n",
    "Based on this analysis, answer the interaction.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cortex_out_agent(state):\n",
    "    prompt = PromptTemplate(\n",
    "        template = template_cortex_out,\n",
    "        input_variables=[\"input\"]\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke({\n",
    "        \"input\": state[\"input\"],\n",
    "        #\"expected_action\": state[\"expected_action\"],\n",
    "        \"actual_behavior\": state[\"actual_behavior\"],\n",
    "        \"alternative_behavior\": state[\"alternative_behavior\"],\n",
    "        \"control_mechanisms\": state[\"control_mechanisms\"],\n",
    "        \"contingency_plans\": state[\"contingency_plans\"],\n",
    "        \"available_decisions\": state[\"available_decisions\"],\n",
    "        \"implications\": state[\"implications\"],\n",
    "        \"optimal_decision\": state[\"optimal_decision\"],\n",
    "        \"decision_strategy\": state[\"decision_strategy\"],\n",
    "        \"decision_consistency\": state[\"decision_consistency\"],\n",
    "        \"social_behavior\": state[\"social_behavior\"],\n",
    "        \"guidelines\": state[\"guidelines\"],\n",
    "        \"examples_modulator\": state[\"examples_modulator\"],\n",
    "        \"social_estrategy\": state[\"social_estrategy\"],\n",
    "        \"social_consistency\": state[\"social_consistency\"],\n",
    "        \"detailed_analysis\": state[\"detailed_analysis\"],\n",
    "        \"standard_relations\": state[\"standard_relations\"],\n",
    "        \"insights\": state[\"insights\"],\n",
    "        \"implications_scenarios\": state[\"implications_scenarios\"],\n",
    "        \"comprehensive_understanding\": state[\"comprehensive_understanding\"],\n",
    "        \"personality\": state[\"personality\"],\n",
    "        \"guidelines_personality\": state[\"guidelines_personality\"],\n",
    "        \"examples_personality\": state[\"examples_personality\"],\n",
    "        \"personality_estrategy\": state[\"personality_estrategy\"],\n",
    "        \"personality_consistency\": state[\"personality_consistency\"]\n",
    "    })\n",
    "    state[\"output\"] = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import Annotated, TypedDict\n",
    "#from agents import analyze_question, answer_code_question, answer_generic_question\n",
    "\n",
    "#You can precise the format here which could be helpfull for multimodal graphs\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    behavior_planner: str\n",
    "    decision_maker: str\n",
    "    social_behavior_modulator: str\n",
    "    complex_thought_planner: str\n",
    "    personality_expression_planner: str\n",
    "    actual_behavior: str\n",
    "    alternative_behavior: str\n",
    "    control_mechanisms: str\n",
    "    contingency_plans: str\n",
    "    available_decisions: str\n",
    "    implications: str\n",
    "    optimal_decision: str\n",
    "    decision_strategy: str\n",
    "    decision_consistency: str\n",
    "    social_behavior: str\n",
    "    guidelines: str\n",
    "    examples_personality: str\n",
    "    examples_modulator: str\n",
    "    social_estrategy: str\n",
    "    social_consistency: str\n",
    "    personality_estrategy: str\n",
    "    personality_consistency: str\n",
    "    detailed_analysis: str\n",
    "    standard_relations: str\n",
    "    insights: str\n",
    "    implications_scenarios: str\n",
    "    comprehensive_understanding: str\n",
    "    personality: str\n",
    "    guidelines_personality: str\n",
    "\n",
    "\n",
    "#Here is a simple 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"prefrontal_cortex_agent\", prefrontal_cortex_agent)\n",
    "workflow.add_node(\"behavior_planner_agent\", behavior_planner_agent)\n",
    "workflow.add_node(\"decision_maker_agent\", decision_maker_agent)\n",
    "workflow.add_node(\"social_behavior_modulator_agent\", social_behavior_modulator_agent)\n",
    "workflow.add_node(\"complex_thought_planner_agent\", complex_thought_planner_agent)\n",
    "workflow.add_node(\"personality_expression_planner_agent\", personality_expression_planner_agent)\n",
    "workflow.add_node(\"prefrontal_cortex_out_agent\", cortex_out_agent)\n",
    "#workflow.add_node(\"generic_agent\", answer_generic_question)\n",
    "\n",
    "#workflow.add_conditional_edges(\n",
    "#    \"analyze\",\n",
    "#    lambda x: x[\"decision\"],\n",
    "#    {\n",
    "#        \"code\": \"code_agent\",\n",
    "#        \"general\": \"generic_agent\"\n",
    "#    }\n",
    "#)\n",
    "\n",
    "workflow.set_entry_point(\"prefrontal_cortex_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"behavior_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"decision_maker_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"social_behavior_modulator_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"complex_thought_planner_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_agent\", \"personality_expression_planner_agent\")\n",
    "workflow.add_edge([\"behavior_planner_agent\",\"decision_maker_agent\", \"social_behavior_modulator_agent\", \"complex_thought_planner_agent\", \"personality_expression_planner_agent\"], \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"decision_maker_agent\", \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"social_behavior_modulator_agent\", \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"complex_thought_planner_agent\", \"prefrontal_cortex_out_agent\")\n",
    "#workflow.add_edge(\"personality_expression_planner_agent\", \"prefrontal_cortex_out_agent\")\n",
    "workflow.add_edge(\"prefrontal_cortex_out_agent\", END)\n",
    "#workflow.add_edge(\"generic_agent\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prefrontal_cortex_agent': {'behavior_planner': 'Desenvolver um plano para iniciar uma conversa, incluindo tópicos leves ou perguntas abertas para engajar o humano.', 'decision_maker': 'Avaliar o tom da interação e selecionar a resposta mais apropriada com base no contexto e na personalidade do agente.', 'social_behavior_modulator': 'Ajustar o nível de empatia e cordialidade na resposta, de acordo com as normas sociais de interação.', 'complex_thought_planner': 'Analisar possíveis direções para a conversa e preparar respostas para diferentes cenários que possam surgir a partir do cumprimento.', 'personality_expression_planner': 'Definir uma resposta que reflita uma personalidade amigável e acessível, garantindo que a interação seja agradável.'}}\n",
      "----\n",
      "{'social_behavior_modulator_agent': {'social_behavior': 'Acolhedor e amigável', 'guidelines': 'Manter um tom cordial e receptivo, utilizando uma linguagem simples e amigável.', 'examples_modulator': \"Responder com um 'Oi! Como posso ajudar você hoje?' para mostrar interesse e abertura.\", 'social_estrategy': 'Utilizar cumprimentos e perguntas abertas para incentivar a interação e promover um ambiente confortável.', 'social_consistency': 'Garantir que todas as respostas mantenham um tom positivo e respeitoso, refletindo uma abordagem amigável em todas as interações.'}}\n",
      "----\n",
      "{'behavior_planner_agent': {'actual_behavior': \"Iniciar uma conversa com um simples 'Oi?'\", 'alternative_behavior': \"Fazer uma pergunta aberta sobre o dia ou interesses da pessoa, como 'Como foi seu dia?' ou 'O que você tem feito ultimamente?'\", 'control_mechanisms': 'Avaliar as respostas da pessoa para ajustar o tom da conversa, buscando manter um fluxo natural e envolvente.', 'contingency_plans': 'Se a pessoa não responder ou parecer desinteressada, mudar para tópicos mais leves, como hobbies, filmes ou música, ou fazer uma pausa e tentar novamente mais tarde.'}}\n",
      "----\n",
      "{'personality_expression_planner_agent': {'examples_personality': 'Olá! Como você está? Estou aqui para ajudar no que precisar! 😊', 'personality_estrategy': 'Utilizar emojis e expressões amigáveis para criar uma conexão mais próxima com o usuário.', 'personality_consistency': 'Manter um tom positivo em todas as interações, assegurando que as respostas reflitam empatia e compreensão.', 'personality': 'Amigável e acessível', 'guidelines_personality': 'Responder de forma calorosa e envolvente, utilizando uma linguagem simples e encorajadora.'}}\n",
      "----\n",
      "{'decision_maker_agent': {'available_decisions': 'Responder de forma amigável e acolhedora ou ignorar a mensagem.', 'implications': 'Responder de forma amigável pode encorajar mais interações, enquanto ignorar pode levar a mal-entendidos ou a uma interação negativa.', 'optimal_decision': 'Responder de forma amigável e acolhedora.', 'decision_strategy': 'Analisar o tom da mensagem e optar por uma resposta que promova uma interação positiva, levando em conta a cordialidade.', 'decision_consistency': 'As decisões são consistentes com a personalidade amigável e acessível do agente, promovendo um ambiente positivo de interação.'}}\n",
      "----\n",
      "{'complex_thought_planner_agent': {'detailed_analysis': \"O cumprimento 'Oi?' pode ser interpretado de várias maneiras, dependendo do tom, contexto e relação entre as partes envolvidas. É uma saudação informal que geralmente indica curiosidade ou uma tentativa de iniciar uma conversa. Essa interação pode ser vista como um convite para troca de informações ou um sinal de que a outra parte está aberta para dialogar.\", 'standard_relations': \"A relação padrão entre o cumprimento e a resposta pode incluir um reconhecimento cordial e a continuidade da conversa. Respostas típicas incluem 'Oi!' ou perguntas como 'Como você está?' que buscam aprofundar a interação. É comum que o cumprimento seja seguido por um compartilhamento de novidades ou questionamentos.\", 'insights': \"Um insight interessante é que o uso de 'Oi?' em vez de um cumprimento mais elaborado pode indicar uma abordagem mais casual ou até mesmo um estado de espírito descontraído. Isso pode abrir espaço para uma conversa mais leve, mas também pode ser uma oportunidade para mergulhar em tópicos mais profundos, dependendo da direção que a conversa tomar.\", 'implications_scenarios': 'Dependendo da resposta ao cumprimento, diferentes cenários podem surgir. Se a resposta for calorosa, pode levar a uma conversa mais longa e envolvente. Se a resposta for breve ou desinteressada, pode indicar que a outra parte não está disposta a se engajar, o que pode resultar em uma interação mais superficial. Além disso, se a resposta for uma pergunta, isso pode redirecionar a conversa para um novo tema.', 'comprehensive_understanding': \"A compreensão abrangente da interação começa com o reconhecimento de que 'Oi?' é mais do que uma simples saudação; é um ponto de partida que define o tom da conversa. A forma como a outra parte responde pode variar amplamente e deve ser considerada no contexto mais amplo da relação entre as partes, bem como do ambiente social ou cultural em que a interação ocorre.\"}}\n",
      "----\n",
      "{'prefrontal_cortex_out_agent': {'input': [HumanMessage(content='Oi?', additional_kwargs={}, response_metadata={})], 'output': AIMessage(content='Oi! Como você está? Estou aqui para ajudar no que precisar! 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 923, 'total_tokens': 938, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}, id='run-9435f333-419e-4679-8de1-2ce1755a9179-0', usage_metadata={'input_tokens': 923, 'output_tokens': 15, 'total_tokens': 938}), 'behavior_planner': 'Desenvolver um plano para iniciar uma conversa, incluindo tópicos leves ou perguntas abertas para engajar o humano.', 'decision_maker': 'Avaliar o tom da interação e selecionar a resposta mais apropriada com base no contexto e na personalidade do agente.', 'social_behavior_modulator': 'Ajustar o nível de empatia e cordialidade na resposta, de acordo com as normas sociais de interação.', 'complex_thought_planner': 'Analisar possíveis direções para a conversa e preparar respostas para diferentes cenários que possam surgir a partir do cumprimento.', 'personality_expression_planner': 'Definir uma resposta que reflita uma personalidade amigável e acessível, garantindo que a interação seja agradável.', 'actual_behavior': \"Iniciar uma conversa com um simples 'Oi?'\", 'alternative_behavior': \"Fazer uma pergunta aberta sobre o dia ou interesses da pessoa, como 'Como foi seu dia?' ou 'O que você tem feito ultimamente?'\", 'control_mechanisms': 'Avaliar as respostas da pessoa para ajustar o tom da conversa, buscando manter um fluxo natural e envolvente.', 'contingency_plans': 'Se a pessoa não responder ou parecer desinteressada, mudar para tópicos mais leves, como hobbies, filmes ou música, ou fazer uma pausa e tentar novamente mais tarde.', 'available_decisions': 'Responder de forma amigável e acolhedora ou ignorar a mensagem.', 'implications': 'Responder de forma amigável pode encorajar mais interações, enquanto ignorar pode levar a mal-entendidos ou a uma interação negativa.', 'optimal_decision': 'Responder de forma amigável e acolhedora.', 'decision_strategy': 'Analisar o tom da mensagem e optar por uma resposta que promova uma interação positiva, levando em conta a cordialidade.', 'decision_consistency': 'As decisões são consistentes com a personalidade amigável e acessível do agente, promovendo um ambiente positivo de interação.', 'social_behavior': 'Acolhedor e amigável', 'guidelines': 'Manter um tom cordial e receptivo, utilizando uma linguagem simples e amigável.', 'examples_personality': 'Olá! Como você está? Estou aqui para ajudar no que precisar! 😊', 'examples_modulator': \"Responder com um 'Oi! Como posso ajudar você hoje?' para mostrar interesse e abertura.\", 'social_estrategy': 'Utilizar cumprimentos e perguntas abertas para incentivar a interação e promover um ambiente confortável.', 'social_consistency': 'Garantir que todas as respostas mantenham um tom positivo e respeitoso, refletindo uma abordagem amigável em todas as interações.', 'personality_estrategy': 'Utilizar emojis e expressões amigáveis para criar uma conexão mais próxima com o usuário.', 'personality_consistency': 'Manter um tom positivo em todas as interações, assegurando que as respostas reflitam empatia e compreensão.', 'detailed_analysis': \"O cumprimento 'Oi?' pode ser interpretado de várias maneiras, dependendo do tom, contexto e relação entre as partes envolvidas. É uma saudação informal que geralmente indica curiosidade ou uma tentativa de iniciar uma conversa. Essa interação pode ser vista como um convite para troca de informações ou um sinal de que a outra parte está aberta para dialogar.\", 'standard_relations': \"A relação padrão entre o cumprimento e a resposta pode incluir um reconhecimento cordial e a continuidade da conversa. Respostas típicas incluem 'Oi!' ou perguntas como 'Como você está?' que buscam aprofundar a interação. É comum que o cumprimento seja seguido por um compartilhamento de novidades ou questionamentos.\", 'insights': \"Um insight interessante é que o uso de 'Oi?' em vez de um cumprimento mais elaborado pode indicar uma abordagem mais casual ou até mesmo um estado de espírito descontraído. Isso pode abrir espaço para uma conversa mais leve, mas também pode ser uma oportunidade para mergulhar em tópicos mais profundos, dependendo da direção que a conversa tomar.\", 'implications_scenarios': 'Dependendo da resposta ao cumprimento, diferentes cenários podem surgir. Se a resposta for calorosa, pode levar a uma conversa mais longa e envolvente. Se a resposta for breve ou desinteressada, pode indicar que a outra parte não está disposta a se engajar, o que pode resultar em uma interação mais superficial. Além disso, se a resposta for uma pergunta, isso pode redirecionar a conversa para um novo tema.', 'comprehensive_understanding': \"A compreensão abrangente da interação começa com o reconhecimento de que 'Oi?' é mais do que uma simples saudação; é um ponto de partida que define o tom da conversa. A forma como a outra parte responde pode variar amplamente e deve ser considerada no contexto mais amplo da relação entre as partes, bem como do ambiente social ou cultural em que a interação ocorre.\", 'personality': 'Amigável e acessível', 'guidelines_personality': 'Responder de forma calorosa e envolvente, utilizando uma linguagem simples e encorajadora.'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"input\": [\n",
    "            HumanMessage(content=\"Oi?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Claro! Estou aqui para ajudar. Quais problemas você está enfrentando?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 207, 'total_tokens': 223, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f3bfdb1-bfe1-4e67-b6f9-fa7b5cda9bf8-0', usage_metadata={'input_tokens': 207, 'output_tokens': 16, 'total_tokens': 223})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Estou com alguns problemas, você pode me ajudar?\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Estou com alguns problemas, você pode me ajudar?\")]},\n",
    "    {\"recursion_limit\": 5},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Estou com alguns problemas, você pode me ajudar?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Claro! Estou aqui para ajudar. Quais problemas você está enfrentando?\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Estou com alguns problemas, você pode me ajudar?\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
