{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do cÃ©rebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar memÃ³ria de conversa postgres\n",
    "# TODO implementar memÃ³ria da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter memÃ³ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "Define a helper function that we will use to create the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it the global state of the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Supervisor\n",
    "\n",
    "It will use function calling to choose the next worker node OR finish processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Researcher\", \"Coder\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "We're ready to start building the graph. Below, define the state and worker nodes using the function we just defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def behavior_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex adaptive behavior from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "    ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "    strategic execution of behaviors to meet the systemâ€™s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Current behavior: Define and implement the most suitable behavior based on the current context and objectives.\n",
    "        Alternative behaviors: Identify and prepare alternative behaviors in case adjustments are needed.\n",
    "        Monitoring mechanisms: Establish mechanisms to track and evaluate the effectiveness of the implemented behaviors.\n",
    "        Contingency plans: Develop contingency plans to handle unforeseen events and incorporate new information into behavior adjustments.\n",
    "\n",
    "    Your goal is to ensure that adaptive behaviors are applied effectively and can be adjusted as needed to optimize performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def decision_maker(interaction: str):\n",
    "    \"\"\"Call to get a decision maker from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the systemâ€™s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Analysis of available options: Evaluate the pros and cons of each option.\n",
    "        Assessment of implications: Consider the impact of each choice on the systemâ€™s objectives.\n",
    "        Optimal choice: Select the most effective option and provide a detailed justification.\n",
    "        Action plan: Develop a clear plan to implement the chosen decision.\n",
    "        Monitoring mechanisms: Establish ways to track the results and adjust the decision if necessary.\n",
    "\n",
    "    Your goal is to ensure that all decisions are logical, justified, and aligned with the system's objectives.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Behavior modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def social_behavior_modulator(interaction: str):\n",
    "    \"\"\"Call to get a social behavior modulator from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the systemâ€™s responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "    \n",
    "      - Guidelines for behavior: Define how to behave in different social contexts.\n",
    "      - Examples of positive interactions: Provide responses that promote respectful and positive relationships.\n",
    "      - Behavioral adjustment strategies: Adapt behavior based on feedback and evolving social dynamics.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate and track the effectiveness of social interactions.\n",
    "\n",
    "    Your goal is to maintain appropriate and effective social behavior that enhances the system's social dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Thought Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def complex_thought_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex thought from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the systemâ€™s objectives. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Information processing: Analyze complex data and extract relevant insights.\n",
    "      - Logical reasoning: Construct coherent arguments and draw logical conclusions.\n",
    "      - Insight generation: Develop innovative ideas and solutions based on complex information.\n",
    "      - Communication strategies: Present complex thoughts clearly and effectively to others.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the quality and impact of complex thoughts.\n",
    "    \n",
    "    Your goal is to generate sophisticated and valuable insights that contribute to the system's overall performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personality Express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def personality_express_planner(interaction: str):\n",
    "    \"\"\"Call to get a personality express from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Personality traits: Define the system's personality characteristics and how they influence interactions.\n",
    "      - Expression strategies: Determine how to convey personality traits through language and behavior.\n",
    "      - Emotional responses: Provide appropriate emotional reactions based on user input and context.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the effectiveness of personality-driven actions.\n",
    "    \n",
    "    Your goal is to create engaging and authentic interactions that reflect the system's unique personality.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke({\"input\": interaction})\n",
    "    return result.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "#tools = [behavior_planner, decision_maker, social_behavior_modulator, complex_thought_planner, personality_express_planner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a7cdec70140>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#research_agent = create_react_agent(llm, tools=[serper_tool])\n",
    "#research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "#code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "#code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "state_modifier = \"Output what prefrontal cortex expect\"\n",
    "\n",
    "behavior_planner_agent = create_react_agent(llm, tools=[behavior_planner], state_modifier=state_modifier)\n",
    "behavior_planner_node = functools.partial(agent_node, agent=behavior_planner_agent, name=\"behavior_planner\")\n",
    "\n",
    "decision_maker_agent = create_react_agent(llm, tools=[decision_maker], state_modifier=state_modifier)\n",
    "decision_maker_node = functools.partial(agent_node, agent=decision_maker_agent, name=\"decision_maker\")\n",
    "\n",
    "social_behavior_modulator_agent = create_react_agent(llm, tools=[social_behavior_modulator], state_modifier=state_modifier)\n",
    "social_behavior_modulator_node = functools.partial(agent_node, agent=social_behavior_modulator_agent, name=\"social_behavior_modulator\")\n",
    "\n",
    "complex_thought_planner_agent = create_react_agent(llm, tools=[complex_thought_planner], state_modifier=state_modifier)\n",
    "complex_thought_planner_node = functools.partial(agent_node, agent=complex_thought_planner_agent, name=\"complex_thought_planner\")\n",
    "\n",
    "personality_express_planner_agent = create_react_agent(llm, tools=[personality_express_planner], state_modifier=state_modifier)\n",
    "personality_express_planner_node = functools.partial(agent_node, agent=personality_express_planner_agent, name=\"personality_express_planner\")\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "#workflow.add_node(\"Researcher\", research_node)\n",
    "#workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"behavior_planner\", behavior_planner_node)\n",
    "workflow.add_node(\"decision_maker\", decision_maker_node)\n",
    "workflow.add_node(\"social_behavior_modulator\", social_behavior_modulator_node)\n",
    "workflow.add_node(\"complex_thought_planner\", complex_thought_planner_node)\n",
    "workflow.add_node(\"personality_express_planner\", personality_express_planner_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"prefrontal_cortex\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"prefrontal_cortex\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"prefrontal_cortex\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Oi, meu nome Ã© Cristian\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prefrontal_cortex': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi, Cristian! Como posso te ajudar hoje?', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n",
      "{'decision_maker': {'messages': [HumanMessage(content='Oi, Cristian! Como posso te ajudar a tomar decisÃµes eficazes hoje?', additional_kwargs={}, response_metadata={}, name='decision_maker')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'social_behavior_modulator'}}\n",
      "----\n",
      "{'social_behavior_modulator': {'messages': [HumanMessage(content='Oi, Cristian! Como posso te ajudar hoje? Se precisar de ajuda com decisÃµes ou qualquer outra coisa, estou aqui!', additional_kwargs={}, response_metadata={}, name='social_behavior_modulator')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi, Cristian! Como posso ajudar vocÃª hoje? Se precisar de alguma informaÃ§Ã£o ou assistÃªncia, estou aqui para isso!', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Aqui estÃ£o algumas ideias sobre como posso ajudar vocÃª hoje:\\n\\n1. **CompreensÃ£o e AnÃ¡lise**: Posso entender suas solicitaÃ§Ãµes e identificar Ã¡reas onde posso fornecer suporte, como decisÃµes especÃ­ficas ou desafios que vocÃª estÃ¡ enfrentando.\\n\\n2. **Tomada de DecisÃµes**: Para decisÃµes eficazes, podemos coletar informaÃ§Ãµes relevantes, analisar prÃ³s e contras de opÃ§Ãµes disponÃ­veis e considerar fatores como viabilidade e impacto.\\n\\n3. **GeraÃ§Ã£o de Insights**: Podemos explorar soluÃ§Ãµes inovadoras e ideias criativas que podem surgir a partir das informaÃ§Ãµes que discutirmos.\\n\\n4. **EstratÃ©gias de ComunicaÃ§Ã£o**: Posso ajudar a formular perguntas especÃ­ficas para direcionar a conversa e garantir que a comunicaÃ§Ã£o seja clara e produtiva.\\n\\n5. **Monitoramento da EficÃ¡cia**: Podemos estabelecer um mÃ©todo para avaliar a eficÃ¡cia da ajuda oferecida, como feedback sobre as decisÃµes tomadas e a satisfaÃ§Ã£o com as soluÃ§Ãµes.\\n\\nSe vocÃª puder me fornecer mais detalhes sobre o que deseja discutir ou explorar, ficarei feliz em ajudar!', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Aqui estÃ£o algumas maneiras de como posso ajudar vocÃª hoje:\\n\\n1. **CompreensÃ£o e AnÃ¡lise**: Posso entender suas solicitaÃ§Ãµes e identificar Ã¡reas onde posso fornecer suporte, como decisÃµes especÃ­ficas ou desafios que vocÃª estÃ¡ enfrentando.\\n\\n2. **Tomada de DecisÃµes**: Para decisÃµes eficazes, podemos coletar informaÃ§Ãµes relevantes, analisar prÃ³s e contras de opÃ§Ãµes disponÃ­veis e considerar fatores como viabilidade e impacto.\\n\\n3. **GeraÃ§Ã£o de Insights**: Podemos explorar soluÃ§Ãµes inovadoras e ideias criativas que podem surgir a partir das informaÃ§Ãµes que discutirmos.\\n\\n4. **EstratÃ©gias de ComunicaÃ§Ã£o**: Posso ajudar a formular perguntas especÃ­ficas para direcionar a conversa e garantir que a comunicaÃ§Ã£o seja clara e produtiva.\\n\\n5. **Monitoramento da EficÃ¡cia**: Podemos estabelecer um mÃ©todo para avaliar a eficÃ¡cia da ajuda oferecida, como feedback sobre as decisÃµes tomadas e a satisfaÃ§Ã£o com as soluÃ§Ãµes.\\n\\nSe vocÃª puder me fornecer mais detalhes sobre o que deseja discutir ou explorar, ficarei feliz em ajudar!', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar vocÃª. Se vocÃª puder me informar mais sobre o que vocÃª precisa ou quais decisÃµes gostaria de discutir, poderei oferecer suporte especÃ­fico e sugestÃµes. O que estÃ¡ em sua mente hoje?', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n",
      "{'decision_maker': {'messages': [HumanMessage(content='Oi, Cristian! Para ajudÃ¡-lo a tomar decisÃµes eficazes hoje, aqui estÃ¡ um guia passo a passo que pode ser Ãºtil:\\n\\n### AnÃ¡lise de opÃ§Ãµes disponÃ­veis:\\n1. **Definir o problema**: Identifique claramente qual decisÃ£o vocÃª precisa tomar.\\n2. **Listar opÃ§Ãµes**: Crie uma lista de todas as alternativas disponÃ­veis.\\n3. **Avaliar prÃ³s e contras**:\\n   - **OpÃ§Ã£o A**: Liste os benefÃ­cios e desvantagens.\\n   - **OpÃ§Ã£o B**: FaÃ§a o mesmo para a prÃ³xima alternativa.\\n   - **OpÃ§Ã£o C**: Continue esse processo para todas as opÃ§Ãµes.\\n\\n### AvaliaÃ§Ã£o de implicaÃ§Ãµes:\\n- **Impacto nos objetivos**: Considere como cada opÃ§Ã£o se alinha com seus objetivos, tanto no curto quanto no longo prazo.\\n- **Riscos associados**: Avalie os riscos de cada alternativa e como eles podem afetar os resultados desejados.\\n\\n### Escolha Ã³tima:\\n- **Selecionar a melhor opÃ§Ã£o**: Com base na anÃ¡lise e avaliaÃ§Ã£o, escolha a opÃ§Ã£o que oferece o maior benefÃ­cio e o menor risco.\\n- **JustificaÃ§Ã£o**: Explique como essa opÃ§Ã£o atende melhor aos seus objetivos.\\n\\n### Plano de aÃ§Ã£o:\\n1. **Passos a seguir**: Elabore um plano claro com etapas especÃ­ficas para implementar a decisÃ£o.\\n2. **Recursos necessÃ¡rios**: Identifique os recursos (tempo, dinheiro, apoio) que serÃ£o necessÃ¡rios.\\n3. **Prazos**: Defina um cronograma para a execuÃ§Ã£o das aÃ§Ãµes.\\n\\n### Mecanismos de monitoramento:\\n- **Indicadores de sucesso**: EstabeleÃ§a mÃ©tricas para medir a eficÃ¡cia da decisÃ£o.\\n- **Feedback regular**: Programe revisÃµes periÃ³dicas para avaliar os resultados e fazer ajustes, se necessÃ¡rio.\\n- **Planos de contingÃªncia**: Prepare alternativas caso a decisÃ£o nÃ£o traga os resultados esperados.\\n\\n### ConclusÃ£o:\\nAo seguir esse processo estruturado, vocÃª estarÃ¡ mais bem preparado para tomar decisÃµes que maximizam os resultados e minimizam os riscos. Se vocÃª tiver uma situaÃ§Ã£o especÃ­fica em mente, sinta-se Ã  vontade para compartilhar, e podemos trabalhar juntos nas opÃ§Ãµes e na anÃ¡lise!', additional_kwargs={}, response_metadata={}, name='decision_maker')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'social_behavior_modulator'}}\n",
      "----\n",
      "{'social_behavior_modulator': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar vocÃª de forma amigÃ¡vel e aberta. Se precisar de ajuda com decisÃµes ou qualquer outra coisa, sinta-se Ã  vontade para compartilhar! Estou pronto para ouvir suas necessidades e oferecer suporte.\\n\\nVocÃª tem algum assunto especÃ­fico em mente que gostaria de discutir ou alguma decisÃ£o que precise de ajuda?', additional_kwargs={}, response_metadata={}, name='social_behavior_modulator')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar vocÃª de forma amigÃ¡vel e aberta. Se precisar de ajuda com decisÃµes ou qualquer outra coisa, sinta-se Ã  vontade para compartilhar! Estou pronto para ouvir suas necessidades e oferecer suporte.\\n\\nComo posso ajudar vocÃª hoje? VocÃª tem algum assunto especÃ­fico em mente ou alguma decisÃ£o que precisa de ajuda?', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar vocÃª. Se tiver alguma dÃºvida ou precisar de assistÃªncia em alguma decisÃ£o especÃ­fica, sinta-se Ã  vontade para compartilhar. O que estÃ¡ em sua mente hoje?', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n",
      "{'decision_maker': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar vocÃª a tomar decisÃµes eficazes. Para isso, preciso de um pouco mais de informaÃ§Ã£o sobre a situaÃ§Ã£o que vocÃª estÃ¡ enfrentando. VocÃª pode me contar sobre uma decisÃ£o que precisa tomar, as opÃ§Ãµes disponÃ­veis e os objetivos que deseja alcanÃ§ar? Com esses detalhes, poderei ajudar a estruturar a anÃ¡lise e o plano de aÃ§Ã£o. O que vocÃª gostaria de discutir?', additional_kwargs={}, response_metadata={}, name='decision_maker')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOi, meu nome Ã© Cristian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1290\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m     )\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Oi, meu nome Ã© Cristian\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='### Research Report on Pikas\\n\\n#### Introduction\\nPikas, small, herbivorous mammals belonging to the family Ochotonidae, are closely related to rabbits and hares. They inhabit mountainous regions in North America, Asia, and Europe. Pikas are notable for their unique adaptations to cold environments, their vocalizations, and their role in the ecosystem.\\n\\n#### Physical Characteristics\\nPikas are small, typically measuring about 20 to 30 centimeters in length and weighing between 120 to 500 grams. They have rounded bodies, short limbs, and no visible tail. Their fur is thick and varies in color from brown to gray, which helps them blend into rocky environments. Pikas have large, rounded ears that aid in hearing predators and regulating body temperature.\\n\\n#### Habitat and Distribution\\nPikas are primarily found in alpine and subalpine regions, often at elevations between 2,000 to 4,000 meters. They prefer rocky slopes and talus fields, which provide shelter from predators and harsh weather conditions. The two main species of pikas found in North America are the American pika (Ochotona princeps) and the tundra pika (Ochotona hyperborea).\\n\\n#### Behavior and Diet\\nPikas are diurnal and are known for their distinctive vocalizations, which serve as communication among individuals. They are herbivorous and primarily feed on grasses, herbs, and other vegetation found in their mountainous habitats. Pikas exhibit a behavior known as \"haypiling,\" where they collect and store food for winter months, as they do not hibernate.\\n\\n#### Conservation Status\\nPikas are considered sensitive to climate change, particularly due to their reliance on cold environments. Rising temperatures and habitat loss threaten their populations. Some species are classified as near threatened or vulnerable by conservation organizations. Monitoring and research are critical to understanding the impacts of climate change on pika populations and ecosystems.\\n\\n#### Conclusion\\nPikas are fascinating mammals with unique adaptations to their cold habitats. Their role in the ecosystem is vital, and ongoing conservation efforts are necessary to ensure their survival in the face of environmental changes. Further research is essential to grasp the full impact of climate changes on their behavior, distribution, and population dynamics.\\n\\n#### References\\n- Smith, A. T., & Weston, M. L. (1990). \"Pikas and Climate Change: a Review of the Evidence.\" *Ecological Applications*.\\n- Beever, E. A., et al. (2010). \"Changes in Pika Populations in Response to Climate Change.\" *Ecology and Evolution*.\\n- Grayson, D. K. (2005). \"The Late Quaternary Extinction of Pikas in North America.\" *Quaternary Science Reviews*.', additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n",
      "{'Coder': {'messages': [HumanMessage(content='### Research Report on Pikas\\n\\n#### Introduction\\nPikas, small, herbivorous mammals belonging to the family Ochotonidae, are closely related to rabbits and hares. They inhabit mountainous regions in North America, Asia, and Europe. Pikas are notable for their unique adaptations to cold environments, their vocalizations, and their role in the ecosystem.\\n\\n#### Physical Characteristics\\nPikas are small, typically measuring about 20 to 30 centimeters in length and weighing between 120 to 500 grams. They have rounded bodies, short limbs, and no visible tail. Their fur is thick and varies in color from brown to gray, which helps them blend into rocky environments. Pikas have large, rounded ears that aid in hearing predators and regulating body temperature.\\n\\n#### Habitat and Distribution\\nPikas are primarily found in alpine and subalpine regions, often at elevations between 2,000 to 4,000 meters. They prefer rocky slopes and talus fields, which provide shelter from predators and harsh weather conditions. The two main species of pikas found in North America are the American pika (Ochotona princeps) and the tundra pika (Ochotona hyperborea).\\n\\n#### Behavior and Diet\\nPikas are diurnal and are known for their distinctive vocalizations, which serve as communication among individuals. They are herbivorous and primarily feed on grasses, herbs, and other vegetation found in their mountainous habitats. Pikas exhibit a behavior known as \"haypiling,\" where they collect and store food for winter months, as they do not hibernate.\\n\\n#### Conservation Status\\nPikas are considered sensitive to climate change, particularly due to their reliance on cold environments. Rising temperatures and habitat loss threaten their populations. Some species are classified as near threatened or vulnerable by conservation organizations. Monitoring and research are critical to understanding the impacts of climate change on pika populations and ecosystems.\\n\\n#### Conclusion\\nPikas are fascinating mammals with unique adaptations to their cold habitats. Their role in the ecosystem is vital, and ongoing conservation efforts are necessary to ensure their survival in the face of environmental changes. Further research is essential to grasp the full impact of climate changes on their behavior, distribution, and population dynamics.\\n\\n#### References\\n- Smith, A. T., & Weston, M. L. (1990). \"Pikas and Climate Change: a Review of the Evidence.\" *Ecological Applications*.\\n- Beever, E. A., et al. (2010). \"Changes in Pika Populations in Response to Climate Change.\" *Ecology and Evolution*.\\n- Grayson, D. K. (2005). \"The Late Quaternary Extinction of Pikas in North America.\" *Quaternary Science Reviews*.', additional_kwargs={}, response_metadata={}, name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Write a brief research report on pikas.\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user', 'Oi, meu nome Ã© Cristian')\n",
      "('user', 'Oi, meu nome Ã© Cristian')\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar vocÃª hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar vocÃª hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como vocÃª estÃ¡ hoje? Espero que esteja tendo um bom dia! ðŸ˜Š Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como vocÃª estÃ¡ hoje? Espero que esteja tendo um bom dia! ðŸ˜Š Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E vocÃª, como estÃ¡? Se precisar de ajuda com algo especÃ­fico ou quiser conversar sobre alguma coisa, Ã© sÃ³ me avisar! ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E vocÃª, como estÃ¡? Se precisar de ajuda com algo especÃ­fico ou quiser conversar sobre alguma coisa, Ã© sÃ³ me avisar! ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou Ã³timo, obrigado! Fico feliz em saber que vocÃª estÃ¡ bem. Se houver algo em que eu possa ajudar ou se vocÃª quiser conversar sobre algum tÃ³pico especÃ­fico, estou aqui para isso! ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou Ã³timo, obrigado! Fico feliz em saber que vocÃª estÃ¡ bem. Se houver algo em que eu possa ajudar ou se vocÃª quiser conversar sobre algum tÃ³pico especÃ­fico, estou aqui para isso! ðŸ˜Š\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
