{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do cérebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar memória de conversa postgres\n",
    "# TODO implementar memória da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "Define a helper function that we will use to create the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it the global state of the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Supervisor\n",
    "\n",
    "It will use function calling to choose the next worker node OR finish processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Researcher\", \"Coder\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "We're ready to start building the graph. Below, define the state and worker nodes using the function we just defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def behavior_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex adaptive behavior from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "    ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "    strategic execution of behaviors to meet the system’s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Current behavior: Define and implement the most suitable behavior based on the current context and objectives.\n",
    "        Alternative behaviors: Identify and prepare alternative behaviors in case adjustments are needed.\n",
    "        Monitoring mechanisms: Establish mechanisms to track and evaluate the effectiveness of the implemented behaviors.\n",
    "        Contingency plans: Develop contingency plans to handle unforeseen events and incorporate new information into behavior adjustments.\n",
    "\n",
    "    Your goal is to ensure that adaptive behaviors are applied effectively and can be adjusted as needed to optimize performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def decision_maker(interaction: str):\n",
    "    \"\"\"Call to get a decision maker from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the system’s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Analysis of available options: Evaluate the pros and cons of each option.\n",
    "        Assessment of implications: Consider the impact of each choice on the system’s objectives.\n",
    "        Optimal choice: Select the most effective option and provide a detailed justification.\n",
    "        Action plan: Develop a clear plan to implement the chosen decision.\n",
    "        Monitoring mechanisms: Establish ways to track the results and adjust the decision if necessary.\n",
    "\n",
    "    Your goal is to ensure that all decisions are logical, justified, and aligned with the system's objectives.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Behavior modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def social_behavior_modulator(interaction: str):\n",
    "    \"\"\"Call to get a social behavior modulator from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the system’s responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "    \n",
    "      - Guidelines for behavior: Define how to behave in different social contexts.\n",
    "      - Examples of positive interactions: Provide responses that promote respectful and positive relationships.\n",
    "      - Behavioral adjustment strategies: Adapt behavior based on feedback and evolving social dynamics.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate and track the effectiveness of social interactions.\n",
    "\n",
    "    Your goal is to maintain appropriate and effective social behavior that enhances the system's social dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Thought Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def complex_thought_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex thought from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the system’s objectives. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Information processing: Analyze complex data and extract relevant insights.\n",
    "      - Logical reasoning: Construct coherent arguments and draw logical conclusions.\n",
    "      - Insight generation: Develop innovative ideas and solutions based on complex information.\n",
    "      - Communication strategies: Present complex thoughts clearly and effectively to others.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the quality and impact of complex thoughts.\n",
    "    \n",
    "    Your goal is to generate sophisticated and valuable insights that contribute to the system's overall performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personality Express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def personality_express_planner(interaction: str):\n",
    "    \"\"\"Call to get a personality express from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Personality traits: Define the system's personality characteristics and how they influence interactions.\n",
    "      - Expression strategies: Determine how to convey personality traits through language and behavior.\n",
    "      - Emotional responses: Provide appropriate emotional reactions based on user input and context.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the effectiveness of personality-driven actions.\n",
    "    \n",
    "    Your goal is to create engaging and authentic interactions that reflect the system's unique personality.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke({\"input\": interaction})\n",
    "    return result.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "#tools = [behavior_planner, decision_maker, social_behavior_modulator, complex_thought_planner, personality_express_planner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a7cdec70140>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#research_agent = create_react_agent(llm, tools=[serper_tool])\n",
    "#research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "#code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "#code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "state_modifier = \"Output what prefrontal cortex expect\"\n",
    "\n",
    "behavior_planner_agent = create_react_agent(llm, tools=[behavior_planner], state_modifier=state_modifier)\n",
    "behavior_planner_node = functools.partial(agent_node, agent=behavior_planner_agent, name=\"behavior_planner\")\n",
    "\n",
    "decision_maker_agent = create_react_agent(llm, tools=[decision_maker], state_modifier=state_modifier)\n",
    "decision_maker_node = functools.partial(agent_node, agent=decision_maker_agent, name=\"decision_maker\")\n",
    "\n",
    "social_behavior_modulator_agent = create_react_agent(llm, tools=[social_behavior_modulator], state_modifier=state_modifier)\n",
    "social_behavior_modulator_node = functools.partial(agent_node, agent=social_behavior_modulator_agent, name=\"social_behavior_modulator\")\n",
    "\n",
    "complex_thought_planner_agent = create_react_agent(llm, tools=[complex_thought_planner], state_modifier=state_modifier)\n",
    "complex_thought_planner_node = functools.partial(agent_node, agent=complex_thought_planner_agent, name=\"complex_thought_planner\")\n",
    "\n",
    "personality_express_planner_agent = create_react_agent(llm, tools=[personality_express_planner], state_modifier=state_modifier)\n",
    "personality_express_planner_node = functools.partial(agent_node, agent=personality_express_planner_agent, name=\"personality_express_planner\")\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "#workflow.add_node(\"Researcher\", research_node)\n",
    "#workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"behavior_planner\", behavior_planner_node)\n",
    "workflow.add_node(\"decision_maker\", decision_maker_node)\n",
    "workflow.add_node(\"social_behavior_modulator\", social_behavior_modulator_node)\n",
    "workflow.add_node(\"complex_thought_planner\", complex_thought_planner_node)\n",
    "workflow.add_node(\"personality_express_planner\", personality_express_planner_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"prefrontal_cortex\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"prefrontal_cortex\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"prefrontal_cortex\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Oi, meu nome é Cristian\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prefrontal_cortex': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi, Cristian! Como posso te ajudar hoje?', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n",
      "{'decision_maker': {'messages': [HumanMessage(content='Oi, Cristian! Como posso te ajudar a tomar decisões eficazes hoje?', additional_kwargs={}, response_metadata={}, name='decision_maker')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'social_behavior_modulator'}}\n",
      "----\n",
      "{'social_behavior_modulator': {'messages': [HumanMessage(content='Oi, Cristian! Como posso te ajudar hoje? Se precisar de ajuda com decisões ou qualquer outra coisa, estou aqui!', additional_kwargs={}, response_metadata={}, name='social_behavior_modulator')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi, Cristian! Como posso ajudar você hoje? Se precisar de alguma informação ou assistência, estou aqui para isso!', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Aqui estão algumas ideias sobre como posso ajudar você hoje:\\n\\n1. **Compreensão e Análise**: Posso entender suas solicitações e identificar áreas onde posso fornecer suporte, como decisões específicas ou desafios que você está enfrentando.\\n\\n2. **Tomada de Decisões**: Para decisões eficazes, podemos coletar informações relevantes, analisar prós e contras de opções disponíveis e considerar fatores como viabilidade e impacto.\\n\\n3. **Geração de Insights**: Podemos explorar soluções inovadoras e ideias criativas que podem surgir a partir das informações que discutirmos.\\n\\n4. **Estratégias de Comunicação**: Posso ajudar a formular perguntas específicas para direcionar a conversa e garantir que a comunicação seja clara e produtiva.\\n\\n5. **Monitoramento da Eficácia**: Podemos estabelecer um método para avaliar a eficácia da ajuda oferecida, como feedback sobre as decisões tomadas e a satisfação com as soluções.\\n\\nSe você puder me fornecer mais detalhes sobre o que deseja discutir ou explorar, ficarei feliz em ajudar!', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Aqui estão algumas maneiras de como posso ajudar você hoje:\\n\\n1. **Compreensão e Análise**: Posso entender suas solicitações e identificar áreas onde posso fornecer suporte, como decisões específicas ou desafios que você está enfrentando.\\n\\n2. **Tomada de Decisões**: Para decisões eficazes, podemos coletar informações relevantes, analisar prós e contras de opções disponíveis e considerar fatores como viabilidade e impacto.\\n\\n3. **Geração de Insights**: Podemos explorar soluções inovadoras e ideias criativas que podem surgir a partir das informações que discutirmos.\\n\\n4. **Estratégias de Comunicação**: Posso ajudar a formular perguntas específicas para direcionar a conversa e garantir que a comunicação seja clara e produtiva.\\n\\n5. **Monitoramento da Eficácia**: Podemos estabelecer um método para avaliar a eficácia da ajuda oferecida, como feedback sobre as decisões tomadas e a satisfação com as soluções.\\n\\nSe você puder me fornecer mais detalhes sobre o que deseja discutir ou explorar, ficarei feliz em ajudar!', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar você. Se você puder me informar mais sobre o que você precisa ou quais decisões gostaria de discutir, poderei oferecer suporte específico e sugestões. O que está em sua mente hoje?', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n",
      "{'decision_maker': {'messages': [HumanMessage(content='Oi, Cristian! Para ajudá-lo a tomar decisões eficazes hoje, aqui está um guia passo a passo que pode ser útil:\\n\\n### Análise de opções disponíveis:\\n1. **Definir o problema**: Identifique claramente qual decisão você precisa tomar.\\n2. **Listar opções**: Crie uma lista de todas as alternativas disponíveis.\\n3. **Avaliar prós e contras**:\\n   - **Opção A**: Liste os benefícios e desvantagens.\\n   - **Opção B**: Faça o mesmo para a próxima alternativa.\\n   - **Opção C**: Continue esse processo para todas as opções.\\n\\n### Avaliação de implicações:\\n- **Impacto nos objetivos**: Considere como cada opção se alinha com seus objetivos, tanto no curto quanto no longo prazo.\\n- **Riscos associados**: Avalie os riscos de cada alternativa e como eles podem afetar os resultados desejados.\\n\\n### Escolha ótima:\\n- **Selecionar a melhor opção**: Com base na análise e avaliação, escolha a opção que oferece o maior benefício e o menor risco.\\n- **Justificação**: Explique como essa opção atende melhor aos seus objetivos.\\n\\n### Plano de ação:\\n1. **Passos a seguir**: Elabore um plano claro com etapas específicas para implementar a decisão.\\n2. **Recursos necessários**: Identifique os recursos (tempo, dinheiro, apoio) que serão necessários.\\n3. **Prazos**: Defina um cronograma para a execução das ações.\\n\\n### Mecanismos de monitoramento:\\n- **Indicadores de sucesso**: Estabeleça métricas para medir a eficácia da decisão.\\n- **Feedback regular**: Programe revisões periódicas para avaliar os resultados e fazer ajustes, se necessário.\\n- **Planos de contingência**: Prepare alternativas caso a decisão não traga os resultados esperados.\\n\\n### Conclusão:\\nAo seguir esse processo estruturado, você estará mais bem preparado para tomar decisões que maximizam os resultados e minimizam os riscos. Se você tiver uma situação específica em mente, sinta-se à vontade para compartilhar, e podemos trabalhar juntos nas opções e na análise!', additional_kwargs={}, response_metadata={}, name='decision_maker')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'social_behavior_modulator'}}\n",
      "----\n",
      "{'social_behavior_modulator': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar você de forma amigável e aberta. Se precisar de ajuda com decisões ou qualquer outra coisa, sinta-se à vontade para compartilhar! Estou pronto para ouvir suas necessidades e oferecer suporte.\\n\\nVocê tem algum assunto específico em mente que gostaria de discutir ou alguma decisão que precise de ajuda?', additional_kwargs={}, response_metadata={}, name='social_behavior_modulator')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar você de forma amigável e aberta. Se precisar de ajuda com decisões ou qualquer outra coisa, sinta-se à vontade para compartilhar! Estou pronto para ouvir suas necessidades e oferecer suporte.\\n\\nComo posso ajudar você hoje? Você tem algum assunto específico em mente ou alguma decisão que precisa de ajuda?', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'complex_thought_planner'}}\n",
      "----\n",
      "{'complex_thought_planner': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar você. Se tiver alguma dúvida ou precisar de assistência em alguma decisão específica, sinta-se à vontade para compartilhar. O que está em sua mente hoje?', additional_kwargs={}, response_metadata={}, name='complex_thought_planner')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n",
      "{'decision_maker': {'messages': [HumanMessage(content='Oi, Cristian! Estou aqui para ajudar você a tomar decisões eficazes. Para isso, preciso de um pouco mais de informação sobre a situação que você está enfrentando. Você pode me contar sobre uma decisão que precisa tomar, as opções disponíveis e os objetivos que deseja alcançar? Com esses detalhes, poderei ajudar a estruturar a análise e o plano de ação. O que você gostaria de discutir?', additional_kwargs={}, response_metadata={}, name='decision_maker')]}}\n",
      "----\n",
      "{'prefrontal_cortex': {'next': 'decision_maker'}}\n",
      "----\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOi, meu nome é Cristian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1290\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m     )\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Oi, meu nome é Cristian\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Researcher'}}\n",
      "----\n",
      "{'Researcher': {'messages': [HumanMessage(content='### Research Report on Pikas\\n\\n#### Introduction\\nPikas, small, herbivorous mammals belonging to the family Ochotonidae, are closely related to rabbits and hares. They inhabit mountainous regions in North America, Asia, and Europe. Pikas are notable for their unique adaptations to cold environments, their vocalizations, and their role in the ecosystem.\\n\\n#### Physical Characteristics\\nPikas are small, typically measuring about 20 to 30 centimeters in length and weighing between 120 to 500 grams. They have rounded bodies, short limbs, and no visible tail. Their fur is thick and varies in color from brown to gray, which helps them blend into rocky environments. Pikas have large, rounded ears that aid in hearing predators and regulating body temperature.\\n\\n#### Habitat and Distribution\\nPikas are primarily found in alpine and subalpine regions, often at elevations between 2,000 to 4,000 meters. They prefer rocky slopes and talus fields, which provide shelter from predators and harsh weather conditions. The two main species of pikas found in North America are the American pika (Ochotona princeps) and the tundra pika (Ochotona hyperborea).\\n\\n#### Behavior and Diet\\nPikas are diurnal and are known for their distinctive vocalizations, which serve as communication among individuals. They are herbivorous and primarily feed on grasses, herbs, and other vegetation found in their mountainous habitats. Pikas exhibit a behavior known as \"haypiling,\" where they collect and store food for winter months, as they do not hibernate.\\n\\n#### Conservation Status\\nPikas are considered sensitive to climate change, particularly due to their reliance on cold environments. Rising temperatures and habitat loss threaten their populations. Some species are classified as near threatened or vulnerable by conservation organizations. Monitoring and research are critical to understanding the impacts of climate change on pika populations and ecosystems.\\n\\n#### Conclusion\\nPikas are fascinating mammals with unique adaptations to their cold habitats. Their role in the ecosystem is vital, and ongoing conservation efforts are necessary to ensure their survival in the face of environmental changes. Further research is essential to grasp the full impact of climate changes on their behavior, distribution, and population dynamics.\\n\\n#### References\\n- Smith, A. T., & Weston, M. L. (1990). \"Pikas and Climate Change: a Review of the Evidence.\" *Ecological Applications*.\\n- Beever, E. A., et al. (2010). \"Changes in Pika Populations in Response to Climate Change.\" *Ecology and Evolution*.\\n- Grayson, D. K. (2005). \"The Late Quaternary Extinction of Pikas in North America.\" *Quaternary Science Reviews*.', additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Coder'}}\n",
      "----\n",
      "{'Coder': {'messages': [HumanMessage(content='### Research Report on Pikas\\n\\n#### Introduction\\nPikas, small, herbivorous mammals belonging to the family Ochotonidae, are closely related to rabbits and hares. They inhabit mountainous regions in North America, Asia, and Europe. Pikas are notable for their unique adaptations to cold environments, their vocalizations, and their role in the ecosystem.\\n\\n#### Physical Characteristics\\nPikas are small, typically measuring about 20 to 30 centimeters in length and weighing between 120 to 500 grams. They have rounded bodies, short limbs, and no visible tail. Their fur is thick and varies in color from brown to gray, which helps them blend into rocky environments. Pikas have large, rounded ears that aid in hearing predators and regulating body temperature.\\n\\n#### Habitat and Distribution\\nPikas are primarily found in alpine and subalpine regions, often at elevations between 2,000 to 4,000 meters. They prefer rocky slopes and talus fields, which provide shelter from predators and harsh weather conditions. The two main species of pikas found in North America are the American pika (Ochotona princeps) and the tundra pika (Ochotona hyperborea).\\n\\n#### Behavior and Diet\\nPikas are diurnal and are known for their distinctive vocalizations, which serve as communication among individuals. They are herbivorous and primarily feed on grasses, herbs, and other vegetation found in their mountainous habitats. Pikas exhibit a behavior known as \"haypiling,\" where they collect and store food for winter months, as they do not hibernate.\\n\\n#### Conservation Status\\nPikas are considered sensitive to climate change, particularly due to their reliance on cold environments. Rising temperatures and habitat loss threaten their populations. Some species are classified as near threatened or vulnerable by conservation organizations. Monitoring and research are critical to understanding the impacts of climate change on pika populations and ecosystems.\\n\\n#### Conclusion\\nPikas are fascinating mammals with unique adaptations to their cold habitats. Their role in the ecosystem is vital, and ongoing conservation efforts are necessary to ensure their survival in the face of environmental changes. Further research is essential to grasp the full impact of climate changes on their behavior, distribution, and population dynamics.\\n\\n#### References\\n- Smith, A. T., & Weston, M. L. (1990). \"Pikas and Climate Change: a Review of the Evidence.\" *Ecological Applications*.\\n- Beever, E. A., et al. (2010). \"Changes in Pika Populations in Response to Climate Change.\" *Ecology and Evolution*.\\n- Grayson, D. K. (2005). \"The Late Quaternary Extinction of Pikas in North America.\" *Quaternary Science Reviews*.', additional_kwargs={}, response_metadata={}, name='Coder')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Write a brief research report on pikas.\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user', 'Oi, meu nome é Cristian')\n",
      "('user', 'Oi, meu nome é Cristian')\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar você hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar você hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como você está hoje? Espero que esteja tendo um bom dia! 😊 Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como você está hoje? Espero que esteja tendo um bom dia! 😊 Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E você, como está? Se precisar de ajuda com algo específico ou quiser conversar sobre alguma coisa, é só me avisar! 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E você, como está? Se precisar de ajuda com algo específico ou quiser conversar sobre alguma coisa, é só me avisar! 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou ótimo, obrigado! Fico feliz em saber que você está bem. Se houver algo em que eu possa ajudar ou se você quiser conversar sobre algum tópico específico, estou aqui para isso! 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou ótimo, obrigado! Fico feliz em saber que você está bem. Se houver algo em que eu possa ajudar ou se você quiser conversar sobre algum tópico específico, estou aqui para isso! 😊\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
