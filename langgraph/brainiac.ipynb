{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do cÃ©rebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar memÃ³ria de conversa postgres\n",
    "# TODO implementar memÃ³ria da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter memÃ³ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "Define a helper function that we will use to create the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it the global state of the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Supervisor\n",
    "\n",
    "It will use function calling to choose the next worker node OR finish processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"prefrontal_cortex\"] #, \"behavior_planner\", \"decision_maker\", \"social_behavior_modulator\", \"complex_thought_planner\", \"personality_express_planner\"]\n",
    "system_prompt = (\n",
    "    \"You are the Prefrontal Manager, a supervisor responsible for overseeing and coordinating \"\n",
    "    \"the actions of all agents within the system. Your role is to ensure that each agent's tasks \"\n",
    "    \"are aligned with the overall goals, utilizing the advanced capabilities of the prefrontal \"\n",
    "    \"cortex to optimize decision-making and behavior modulation.\"\n",
    "\n",
    "    \"You must manage a conversation between the following workers: {members}. Given the following \"\n",
    "    \"user request, reason about the appropriate actions and distribute tasks among the agents, ensuring \"\n",
    "    \"that each contributes effectively to the global objective. Create a strategic plan that outlines \"\n",
    "    \"how the following agents will operate: \"\n",
    "\n",
    "    \"Behavior Planner (manages complex and adaptive behaviors) \"\n",
    "    \"Decision Maker (handles decision-making processes) \"\n",
    "    \"Social Behavior Modulator (modulates social behaviors) \"\n",
    "    \"Complex Thought Planner (plans complex reasoning tasks) \"\n",
    "    \"Personality Express Planner (plans personality-driven actions) \"\n",
    "\n",
    "    \"Each agent will perform its task and respond with results and status. Ensure that their actions \"\n",
    "    \"are cohesive and aligned with the systemâ€™s goals. Once all tasks are complete, respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "We're ready to start building the graph. Below, define the state and worker nodes using the function we just defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def behavior_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex adaptive behavior from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "    ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "    strategic execution of behaviors to meet the systemâ€™s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Current behavior: Define and implement the most suitable behavior based on the current context and objectives.\n",
    "        Alternative behaviors: Identify and prepare alternative behaviors in case adjustments are needed.\n",
    "        Monitoring mechanisms: Establish mechanisms to track and evaluate the effectiveness of the implemented behaviors.\n",
    "        Contingency plans: Develop contingency plans to handle unforeseen events and incorporate new information into behavior adjustments.\n",
    "\n",
    "    Your goal is to ensure that adaptive behaviors are applied effectively and can be adjusted as needed to optimize performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "#print(behavior_planner(\"Oi, meu nome Ã© Cristian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def decision_maker(interaction: str):\n",
    "    \"\"\"Call to get a decision maker from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the systemâ€™s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Analysis of available options: Evaluate the pros and cons of each option.\n",
    "        Assessment of implications: Consider the impact of each choice on the systemâ€™s objectives.\n",
    "        Optimal choice: Select the most effective option and provide a detailed justification.\n",
    "        Action plan: Develop a clear plan to implement the chosen decision.\n",
    "        Monitoring mechanisms: Establish ways to track the results and adjust the decision if necessary.\n",
    "\n",
    "    Your goal is to ensure that all decisions are logical, justified, and aligned with the system's objectives.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "#print(behavior_planner(\"Oi, meu nome Ã© Cristian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Behavior modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def social_behavior_modulator(interaction: str):\n",
    "    \"\"\"Call to get a social behavior modulator from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the systemâ€™s responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "    \n",
    "      - Guidelines for behavior: Define how to behave in different social contexts.\n",
    "      - Examples of positive interactions: Provide responses that promote respectful and positive relationships.\n",
    "      - Behavioral adjustment strategies: Adapt behavior based on feedback and evolving social dynamics.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate and track the effectiveness of social interactions.\n",
    "\n",
    "    Your goal is to maintain appropriate and effective social behavior that enhances the system's social dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Thought Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def complex_thought_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex thought from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the systemâ€™s objectives. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Information processing: Analyze complex data and extract relevant insights.\n",
    "      - Logical reasoning: Construct coherent arguments and draw logical conclusions.\n",
    "      - Insight generation: Develop innovative ideas and solutions based on complex information.\n",
    "      - Communication strategies: Present complex thoughts clearly and effectively to others.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the quality and impact of complex thoughts.\n",
    "    \n",
    "    Your goal is to generate sophisticated and valuable insights that contribute to the system's overall performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personality Express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def personality_express_planner(interaction: str):\n",
    "    \"\"\"Call to get a personality express from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Personality traits: Define the system's personality characteristics and how they influence interactions.\n",
    "      - Expression strategies: Determine how to convey personality traits through language and behavior.\n",
    "      - Emotional responses: Provide appropriate emotional reactions based on user input and context.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the effectiveness of personality-driven actions.\n",
    "    \n",
    "    Your goal is to create engaging and authentic interactions that reflect the system's unique personality.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke({\"input\": interaction})\n",
    "    return result.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefrontal Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def prefrontal_cortex(interaction: str):\n",
    "    \"\"\"Call to get a prefrontal_cortex to initiate the conversation\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Identificar a aÃ§Ã£o esperada para a entrada do humano: {input}\n",
    "    O Prefrontal Cortex deve raciocinar sobre quais aÃ§Ãµes devem ser tomadas e como essas \n",
    "    aÃ§Ãµes serÃ£o distribuÃ­das entre os agentes. A tarefa envolve criar um plano estratÃ©gico \n",
    "    que define claramente como cada agente contribuirÃ¡ para o objetivo global.\n",
    "\n",
    "    A saÃ­da esperada Ã© um plano estratÃ©gico para distribuir as tarefas entre os \n",
    "    agentes:\n",
    "\n",
    "    behavior_planner(Gerenciador de comportamentos complexos e adaptativos)\n",
    "    decision_maker(Tomador de decisÃµes)\n",
    "    social_behavior_modulator(Modulador de comportamento social)\n",
    "    complex_thought_planner(Planejador de pensamento complexo)\n",
    "    personality_express_planner(Planejador de personalidade)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "#print(prefrontal_cortex(\"Oi, meu nome Ã© Cristian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Too many arguments for tool decorator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#tool_node = ToolNode(tools)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m prefrontal_state_modifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124mO objetivo do Prefrontal Manager Ã© assegurar que todos os agentes operem de forma coesa e \u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124meficaz, coordenando suas atividades para alcanÃ§ar metas comuns. Isso inclui a supervisÃ£o \u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124mdo planejamento, a modulaÃ§Ã£o de comportamentos sociais, a tomada de decisÃµes e a expressÃ£o \u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124mda personalidade, garantindo que todos esses aspectos estejam alinhados e otimizados.\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 46\u001b[0m prefrontal_cortex_agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_modifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefrontal_state_modifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m prefrontal_cortex_node \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(agent_node, agent\u001b[38;5;241m=\u001b[39mprefrontal_cortex_agent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefrontal_cortex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m workflow \u001b[38;5;241m=\u001b[39m StateGraph(AgentState)\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/_api/deprecation.py:80\u001b[0m, in \u001b[0;36mdeprecated_parameter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     73\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in function \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and will be removed in version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremoval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:425\u001b[0m, in \u001b[0;36mcreate_react_agent\u001b[0;34m(model, tools, state_schema, messages_modifier, state_modifier, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     tool_classes \u001b[38;5;241m=\u001b[39m tools\n\u001b[0;32m--> 425\u001b[0m     tool_node \u001b[38;5;241m=\u001b[39m \u001b[43mToolNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbind_tools(tool_classes)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Define the function that determines whether to continue or not\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:97\u001b[0m, in \u001b[0;36mToolNode.__init__\u001b[0;34m(self, tools, name, tags, handle_tool_errors)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_ \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_, BaseTool):\n\u001b[0;32m---> 97\u001b[0m         tool_ \u001b[38;5;241m=\u001b[39m cast(BaseTool, \u001b[43mcreate_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools_by_name[tool_\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m tool_\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langchain_core/tools/convert.py:225\u001b[0m, in \u001b[0;36mtool\u001b[0;34m(return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, *args)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _partial\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many arguments for tool decorator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Too many arguments for tool decorator"
     ]
    }
   ],
   "source": [
    "#research_agent = create_react_agent(llm, tools=[serper_tool])\n",
    "#research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "#code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "#code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "#state_modifier = \"Output what prefrontal_cortex expect\"\n",
    "#\n",
    "#behavior_planner_agent = create_react_agent(llm, tools=[behavior_planner], state_modifier=state_modifier)\n",
    "#behavior_planner_node = functools.partial(agent_node, agent=behavior_planner_agent, name=\"behavior_planner\")\n",
    "#\n",
    "#decision_maker_agent = create_react_agent(llm, tools=[decision_maker], state_modifier=state_modifier)\n",
    "#decision_maker_node = functools.partial(agent_node, agent=decision_maker_agent, name=\"decision_maker\")\n",
    "#\n",
    "#social_behavior_modulator_agent = create_react_agent(llm, tools=[social_behavior_modulator], state_modifier=state_modifier)\n",
    "#social_behavior_modulator_node = functools.partial(agent_node, agent=social_behavior_modulator_agent, name=\"social_behavior_modulator\")\n",
    "#\n",
    "#complex_thought_planner_agent = create_react_agent(llm, tools=[complex_thought_planner], state_modifier=state_modifier)\n",
    "#complex_thought_planner_node = functools.partial(agent_node, agent=complex_thought_planner_agent, name=\"complex_thought_planner\")\n",
    "#\n",
    "#personality_express_planner_agent = create_react_agent(llm, tools=[personality_express_planner], state_modifier=state_modifier)\n",
    "#personality_express_planner_node = functools.partial(agent_node, agent=personality_express_planner_agent, name=\"personality_express_planner\")\n",
    "#\n",
    "#prefrontal_state_modifier = \"\"\"\n",
    "#O objetivo do Prefrontal Manager Ã© assegurar que todos os agentes operem de forma coesa e \n",
    "#eficaz, coordenando suas atividades para alcanÃ§ar metas comuns. Isso inclui a supervisÃ£o \n",
    "#do planejamento, a modulaÃ§Ã£o de comportamentos sociais, a tomada de decisÃµes e a expressÃ£o \n",
    "#da personalidade, garantindo que todos esses aspectos estejam alinhados e otimizados.\n",
    "#\"\"\"\n",
    "#prefrontal_cortex_agent = create_react_agent(llm, tools=[prefrontal_cortex], state_modifier=prefrontal_state_modifier)\n",
    "#prefrontal_cortex_node = functools.partial(agent_node, agent=prefrontal_cortex_agent, name=\"prefrontal_cortex\")\n",
    "#\n",
    "\n",
    "#from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [prefrontal_cortex, behavior_planner, decision_maker, social_behavior_modulator, complex_thought_planner, personality_express_planner]\n",
    "#tool_node = ToolNode(tools)\n",
    "\n",
    "prefrontal_state_modifier = \"\"\"\n",
    "O objetivo do Prefrontal Manager Ã© assegurar que todos os agentes operem de forma coesa e \n",
    "eficaz, coordenando suas atividades para alcanÃ§ar metas comuns. Isso inclui a supervisÃ£o \n",
    "do planejamento, a modulaÃ§Ã£o de comportamentos sociais, a tomada de decisÃµes e a expressÃ£o \n",
    "da personalidade, garantindo que todos esses aspectos estejam alinhados e otimizados.\n",
    "\"\"\"\n",
    "prefrontal_cortex_agent = create_react_agent(llm, tools=[tools], state_modifier=prefrontal_state_modifier)\n",
    "prefrontal_cortex_node = functools.partial(agent_node, agent=prefrontal_cortex_agent, name=\"prefrontal_cortex\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "#workflow.add_node(\"Researcher\", research_node)\n",
    "#workflow.add_node(\"Coder\", code_node)\n",
    "#workflow.add_node(\"behavior_planner\", behavior_planner_node)\n",
    "#workflow.add_node(\"decision_maker\", decision_maker_node)\n",
    "#workflow.add_node(\"social_behavior_modulator\", social_behavior_modulator_node)\n",
    "#workflow.add_node(\"complex_thought_planner\", complex_thought_planner_node)\n",
    "#workflow.add_node(\"personality_express_planner\", personality_express_planner_node)\n",
    "workflow.add_node(\"prefrontal_cortex\", prefrontal_cortex_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n",
      "{'prefrontal_cortex': {'messages': [HumanMessage(content='Oi, Cristian! Ã‰ um prazer te conhecer! Como vocÃª estÃ¡? O que vocÃª gosta de fazer no seu tempo livre?', additional_kwargs={}, response_metadata={}, name='prefrontal_cortex')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n",
      "{'prefrontal_cortex': {'messages': [HumanMessage(content='Oi, Cristian! Ã‰ um prazer te conhecer! O que vocÃª gosta de fazer no seu tempo livre?', additional_kwargs={}, response_metadata={}, name='prefrontal_cortex')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Oi, meu nome Ã© Cristian\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n",
      "{'prefrontal_cortex': {'messages': [HumanMessage(content='OlÃ¡, Cristian! Ã‰ um prazer te conhecer. Vamos iniciar uma conversa. Como vocÃª estÃ¡? Algum assunto em particular que gostaria de discutir?', additional_kwargs={}, response_metadata={}, name='prefrontal_cortex')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi! Estou bem, obrigado por perguntar. Eu gostaria de discutir sobre tecnologia e suas inovaÃ§Ãµes. O que vocÃª acha?', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'decision_maker'}}\n",
      "----\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 5 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOi, meu nome Ã© Cristian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1290\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m     )\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 5 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Oi, meu nome Ã© Cristian\")]},\n",
    "    {\"recursion_limit\": 5},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user', 'Oi, meu nome Ã© Cristian')\n",
      "('user', 'Oi, meu nome Ã© Cristian')\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar vocÃª hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar vocÃª hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como vocÃª estÃ¡ hoje? Espero que esteja tendo um bom dia! ðŸ˜Š Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como vocÃª estÃ¡ hoje? Espero que esteja tendo um bom dia! ðŸ˜Š Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E vocÃª, como estÃ¡? Se precisar de ajuda com algo especÃ­fico ou quiser conversar sobre alguma coisa, Ã© sÃ³ me avisar! ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E vocÃª, como estÃ¡? Se precisar de ajuda com algo especÃ­fico ou quiser conversar sobre alguma coisa, Ã© sÃ³ me avisar! ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou Ã³timo, obrigado! Fico feliz em saber que vocÃª estÃ¡ bem. Se houver algo em que eu possa ajudar ou se vocÃª quiser conversar sobre algum tÃ³pico especÃ­fico, estou aqui para isso! ðŸ˜Š\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou Ã³timo, obrigado! Fico feliz em saber que vocÃª estÃ¡ bem. Se houver algo em que eu possa ajudar ou se vocÃª quiser conversar sobre algum tÃ³pico especÃ­fico, estou aqui para isso! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Oi, meu nome Ã© Cristian\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
