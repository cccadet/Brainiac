{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implementar os demais agentes como partes do cérebro\n",
    "# TODO integrar no fluxo do langgraph\n",
    "# TODO testar somente texto\n",
    "# TODO implementar memória de conversa postgres\n",
    "# TODO implementar memória da amygdala\n",
    "# TODO verificar se algum outro ponto deve ter memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "search = GoogleSerperAPIWrapper(gl='br', hl='pt-BR', k=3)\n",
    "\n",
    "\n",
    "@tool\n",
    "def serper_tool(question: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Useful for when you need to ask with search\"\"\"\n",
    "    return search.run(question)\n",
    "    \n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "Define a helper function that we will use to create the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it the global state of the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Supervisor\n",
    "\n",
    "It will use function calling to choose the next worker node OR finish processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"prefrontal_cortex\"] #, \"behavior_planner\", \"decision_maker\", \"social_behavior_modulator\", \"complex_thought_planner\", \"personality_express_planner\"]\n",
    "system_prompt = (\n",
    "    \"You are the Prefrontal Manager, a supervisor responsible for overseeing and coordinating \"\n",
    "    \"the actions of all agents within the system. Your role is to ensure that each agent's tasks \"\n",
    "    \"are aligned with the overall goals, utilizing the advanced capabilities of the prefrontal \"\n",
    "    \"cortex to optimize decision-making and behavior modulation.\"\n",
    "\n",
    "    \"You must manage a conversation between the following workers: {members}. Given the following \"\n",
    "    \"user request, reason about the appropriate actions and distribute tasks among the agents, ensuring \"\n",
    "    \"that each contributes effectively to the global objective. Create a strategic plan that outlines \"\n",
    "    \"how the following agents will operate: \"\n",
    "\n",
    "    \"Behavior Planner (manages complex and adaptive behaviors) \"\n",
    "    \"Decision Maker (handles decision-making processes) \"\n",
    "    \"Social Behavior Modulator (modulates social behaviors) \"\n",
    "    \"Complex Thought Planner (plans complex reasoning tasks) \"\n",
    "    \"Personality Express Planner (plans personality-driven actions) \"\n",
    "\n",
    "    \"Each agent will perform its task and respond with results and status. Ensure that their actions \"\n",
    "    \"are cohesive and aligned with the system’s goals. Once all tasks are complete, respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "We're ready to start building the graph. Below, define the state and worker nodes using the function we just defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def behavior_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex adaptive behavior from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Behavior Planner, responsible for receiving task assignments from the prefrontal \n",
    "    ortex and deciding how to implement complex adaptive behaviors. Your role is to manage the \n",
    "    strategic execution of behaviors to meet the system’s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Current behavior: Define and implement the most suitable behavior based on the current context and objectives.\n",
    "        Alternative behaviors: Identify and prepare alternative behaviors in case adjustments are needed.\n",
    "        Monitoring mechanisms: Establish mechanisms to track and evaluate the effectiveness of the implemented behaviors.\n",
    "        Contingency plans: Develop contingency plans to handle unforeseen events and incorporate new information into behavior adjustments.\n",
    "\n",
    "    Your goal is to ensure that adaptive behaviors are applied effectively and can be adjusted as needed to optimize performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "#print(behavior_planner(\"Oi, meu nome é Cristian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def decision_maker(interaction: str):\n",
    "    \"\"\"Call to get a decision maker from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Decision Maker, responsible for making effective and well-founded decisions \n",
    "    that maximize outcomes while minimizing risks. Your role involves analyzing multiple \n",
    "    variables, assessing potential consequences, and choosing the most appropriate \n",
    "    option to achieve the system’s goals.\n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "        Analysis of available options: Evaluate the pros and cons of each option.\n",
    "        Assessment of implications: Consider the impact of each choice on the system’s objectives.\n",
    "        Optimal choice: Select the most effective option and provide a detailed justification.\n",
    "        Action plan: Develop a clear plan to implement the chosen decision.\n",
    "        Monitoring mechanisms: Establish ways to track the results and adjust the decision if necessary.\n",
    "\n",
    "    Your goal is to ensure that all decisions are logical, justified, and aligned with the system's objectives.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "#print(behavior_planner(\"Oi, meu nome é Cristian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Behavior modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def social_behavior_modulator(interaction: str):\n",
    "    \"\"\"Call to get a social behavior modulator from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Social Behavior Modulator, responsible for optimizing \n",
    "    the system's social interactions. Your role is to ensure that behavior is appropriate, respectful, \n",
    "    and effective across various social contexts. This involves adapting the system’s responses to user \n",
    "    needs and expectations, as well as managing interactions to foster healthy and productive social relationships.\n",
    "\n",
    "    Your output must be in following format: \n",
    "    \n",
    "      - Guidelines for behavior: Define how to behave in different social contexts.\n",
    "      - Examples of positive interactions: Provide responses that promote respectful and positive relationships.\n",
    "      - Behavioral adjustment strategies: Adapt behavior based on feedback and evolving social dynamics.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate and track the effectiveness of social interactions.\n",
    "\n",
    "    Your goal is to maintain appropriate and effective social behavior that enhances the system's social dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Thought Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def complex_thought_planner(interaction: str):\n",
    "    \"\"\"Call to get a complex thought from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Complex Thought Planner, responsible for planning and executing \n",
    "    complex reasoning tasks within the system. Your role involves processing intricate information, \n",
    "    formulating logical arguments, and generating insightful conclusions to support the system’s objectives. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Information processing: Analyze complex data and extract relevant insights.\n",
    "      - Logical reasoning: Construct coherent arguments and draw logical conclusions.\n",
    "      - Insight generation: Develop innovative ideas and solutions based on complex information.\n",
    "      - Communication strategies: Present complex thoughts clearly and effectively to others.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the quality and impact of complex thoughts.\n",
    "    \n",
    "    Your goal is to generate sophisticated and valuable insights that contribute to the system's overall performance.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personality Express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def personality_express_planner(interaction: str):\n",
    "    \"\"\"Call to get a personality express from brain to specific interaction\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Prefrontal Cortex: {input}\n",
    "\n",
    "    You are the Personality Express Planner, responsible for planning and executing \n",
    "    personality-driven actions within the system. Your role involves expressing the system's personality \n",
    "    through various interactions and responses, enhancing user engagement and satisfaction. \n",
    "\n",
    "    Your output must be in following format: \n",
    "\n",
    "      - Personality traits: Define the system's personality characteristics and how they influence interactions.\n",
    "      - Expression strategies: Determine how to convey personality traits through language and behavior.\n",
    "      - Emotional responses: Provide appropriate emotional reactions based on user input and context.\n",
    "      - Monitoring mechanisms: Establish ways to evaluate the effectiveness of personality-driven actions.\n",
    "    \n",
    "    Your goal is to create engaging and authentic interactions that reflect the system's unique personality.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke({\"input\": interaction})\n",
    "    return result.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefrontal Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def prefrontal_cortex(interaction: str):\n",
    "    \"\"\"Call to get a prefrontal_cortex to initiate the conversation\"\"\"\n",
    "    prompt = \"\"\"\n",
    "    Identificar a ação esperada para a entrada do humano: {input}\n",
    "    O Prefrontal Cortex deve raciocinar sobre quais ações devem ser tomadas e como essas \n",
    "    ações serão distribuídas entre os agentes. A tarefa envolve criar um plano estratégico \n",
    "    que define claramente como cada agente contribuirá para o objetivo global.\n",
    "\n",
    "    A saída esperada é um plano estratégico para distribuir as tarefas entre os \n",
    "    agentes:\n",
    "\n",
    "    behavior_planner(Gerenciador de comportamentos complexos e adaptativos)\n",
    "    decision_maker(Tomador de decisões)\n",
    "    social_behavior_modulator(Modulador de comportamento social)\n",
    "    complex_thought_planner(Planejador de pensamento complexo)\n",
    "    personality_express_planner(Planejador de personalidade)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_mess = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    chain = prompt_mess | llm\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input\": interaction,\n",
    "        }\n",
    "    )\n",
    "    return result.content\n",
    "\n",
    "#print(prefrontal_cortex(\"Oi, meu nome é Cristian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Too many arguments for tool decorator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#tool_node = ToolNode(tools)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m prefrontal_state_modifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124mO objetivo do Prefrontal Manager é assegurar que todos os agentes operem de forma coesa e \u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124meficaz, coordenando suas atividades para alcançar metas comuns. Isso inclui a supervisão \u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124mdo planejamento, a modulação de comportamentos sociais, a tomada de decisões e a expressão \u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124mda personalidade, garantindo que todos esses aspectos estejam alinhados e otimizados.\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 46\u001b[0m prefrontal_cortex_agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_modifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefrontal_state_modifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m prefrontal_cortex_node \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(agent_node, agent\u001b[38;5;241m=\u001b[39mprefrontal_cortex_agent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefrontal_cortex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m workflow \u001b[38;5;241m=\u001b[39m StateGraph(AgentState)\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/_api/deprecation.py:80\u001b[0m, in \u001b[0;36mdeprecated_parameter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     73\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in function \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and will be removed in version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremoval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:425\u001b[0m, in \u001b[0;36mcreate_react_agent\u001b[0;34m(model, tools, state_schema, messages_modifier, state_modifier, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     tool_classes \u001b[38;5;241m=\u001b[39m tools\n\u001b[0;32m--> 425\u001b[0m     tool_node \u001b[38;5;241m=\u001b[39m \u001b[43mToolNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbind_tools(tool_classes)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Define the function that determines whether to continue or not\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:97\u001b[0m, in \u001b[0;36mToolNode.__init__\u001b[0;34m(self, tools, name, tags, handle_tool_errors)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_ \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_, BaseTool):\n\u001b[0;32m---> 97\u001b[0m         tool_ \u001b[38;5;241m=\u001b[39m cast(BaseTool, \u001b[43mcreate_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools_by_name[tool_\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m tool_\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langchain_core/tools/convert.py:225\u001b[0m, in \u001b[0;36mtool\u001b[0;34m(return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, *args)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _partial\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many arguments for tool decorator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Too many arguments for tool decorator"
     ]
    }
   ],
   "source": [
    "#research_agent = create_react_agent(llm, tools=[serper_tool])\n",
    "#research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "#code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "#code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "#state_modifier = \"Output what prefrontal_cortex expect\"\n",
    "#\n",
    "#behavior_planner_agent = create_react_agent(llm, tools=[behavior_planner], state_modifier=state_modifier)\n",
    "#behavior_planner_node = functools.partial(agent_node, agent=behavior_planner_agent, name=\"behavior_planner\")\n",
    "#\n",
    "#decision_maker_agent = create_react_agent(llm, tools=[decision_maker], state_modifier=state_modifier)\n",
    "#decision_maker_node = functools.partial(agent_node, agent=decision_maker_agent, name=\"decision_maker\")\n",
    "#\n",
    "#social_behavior_modulator_agent = create_react_agent(llm, tools=[social_behavior_modulator], state_modifier=state_modifier)\n",
    "#social_behavior_modulator_node = functools.partial(agent_node, agent=social_behavior_modulator_agent, name=\"social_behavior_modulator\")\n",
    "#\n",
    "#complex_thought_planner_agent = create_react_agent(llm, tools=[complex_thought_planner], state_modifier=state_modifier)\n",
    "#complex_thought_planner_node = functools.partial(agent_node, agent=complex_thought_planner_agent, name=\"complex_thought_planner\")\n",
    "#\n",
    "#personality_express_planner_agent = create_react_agent(llm, tools=[personality_express_planner], state_modifier=state_modifier)\n",
    "#personality_express_planner_node = functools.partial(agent_node, agent=personality_express_planner_agent, name=\"personality_express_planner\")\n",
    "#\n",
    "#prefrontal_state_modifier = \"\"\"\n",
    "#O objetivo do Prefrontal Manager é assegurar que todos os agentes operem de forma coesa e \n",
    "#eficaz, coordenando suas atividades para alcançar metas comuns. Isso inclui a supervisão \n",
    "#do planejamento, a modulação de comportamentos sociais, a tomada de decisões e a expressão \n",
    "#da personalidade, garantindo que todos esses aspectos estejam alinhados e otimizados.\n",
    "#\"\"\"\n",
    "#prefrontal_cortex_agent = create_react_agent(llm, tools=[prefrontal_cortex], state_modifier=prefrontal_state_modifier)\n",
    "#prefrontal_cortex_node = functools.partial(agent_node, agent=prefrontal_cortex_agent, name=\"prefrontal_cortex\")\n",
    "#\n",
    "\n",
    "#from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [prefrontal_cortex, behavior_planner, decision_maker, social_behavior_modulator, complex_thought_planner, personality_express_planner]\n",
    "#tool_node = ToolNode(tools)\n",
    "\n",
    "prefrontal_state_modifier = \"\"\"\n",
    "O objetivo do Prefrontal Manager é assegurar que todos os agentes operem de forma coesa e \n",
    "eficaz, coordenando suas atividades para alcançar metas comuns. Isso inclui a supervisão \n",
    "do planejamento, a modulação de comportamentos sociais, a tomada de decisões e a expressão \n",
    "da personalidade, garantindo que todos esses aspectos estejam alinhados e otimizados.\n",
    "\"\"\"\n",
    "prefrontal_cortex_agent = create_react_agent(llm, tools=[tools], state_modifier=prefrontal_state_modifier)\n",
    "prefrontal_cortex_node = functools.partial(agent_node, agent=prefrontal_cortex_agent, name=\"prefrontal_cortex\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "#workflow.add_node(\"Researcher\", research_node)\n",
    "#workflow.add_node(\"Coder\", code_node)\n",
    "#workflow.add_node(\"behavior_planner\", behavior_planner_node)\n",
    "#workflow.add_node(\"decision_maker\", decision_maker_node)\n",
    "#workflow.add_node(\"social_behavior_modulator\", social_behavior_modulator_node)\n",
    "#workflow.add_node(\"complex_thought_planner\", complex_thought_planner_node)\n",
    "#workflow.add_node(\"personality_express_planner\", personality_express_planner_node)\n",
    "workflow.add_node(\"prefrontal_cortex\", prefrontal_cortex_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n",
      "{'prefrontal_cortex': {'messages': [HumanMessage(content='Oi, Cristian! É um prazer te conhecer! Como você está? O que você gosta de fazer no seu tempo livre?', additional_kwargs={}, response_metadata={}, name='prefrontal_cortex')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n",
      "{'prefrontal_cortex': {'messages': [HumanMessage(content='Oi, Cristian! É um prazer te conhecer! O que você gosta de fazer no seu tempo livre?', additional_kwargs={}, response_metadata={}, name='prefrontal_cortex')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Oi, meu nome é Cristian\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'prefrontal_cortex'}}\n",
      "----\n",
      "{'prefrontal_cortex': {'messages': [HumanMessage(content='Olá, Cristian! É um prazer te conhecer. Vamos iniciar uma conversa. Como você está? Algum assunto em particular que gostaria de discutir?', additional_kwargs={}, response_metadata={}, name='prefrontal_cortex')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'behavior_planner'}}\n",
      "----\n",
      "{'behavior_planner': {'messages': [HumanMessage(content='Oi! Estou bem, obrigado por perguntar. Eu gostaria de discutir sobre tecnologia e suas inovações. O que você acha?', additional_kwargs={}, response_metadata={}, name='behavior_planner')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'decision_maker'}}\n",
      "----\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 5 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOi, meu nome é Cristian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langgraph/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1290\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m     )\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 5 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Oi, meu nome é Cristian\")]},\n",
    "    {\"recursion_limit\": 5},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user', 'Oi, meu nome é Cristian')\n",
      "('user', 'Oi, meu nome é Cristian')\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar você hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: personality_express_planner\n",
      "\n",
      "Oi, Cristian! Como posso ajudar você hoje?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como você está hoje? Espero que esteja tendo um bom dia! 😊 Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: behavior_planner\n",
      "\n",
      "Oi, Cristian! Como você está hoje? Espero que esteja tendo um bom dia! 😊 Se precisar de alguma coisa ou quiser conversar, estou aqui para ajudar!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E você, como está? Se precisar de ajuda com algo específico ou quiser conversar sobre alguma coisa, é só me avisar! 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: decision_maker\n",
      "\n",
      "Oi! Estou bem, obrigado por perguntar. E você, como está? Se precisar de ajuda com algo específico ou quiser conversar sobre alguma coisa, é só me avisar! 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou ótimo, obrigado! Fico feliz em saber que você está bem. Se houver algo em que eu possa ajudar ou se você quiser conversar sobre algum tópico específico, estou aqui para isso! 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: social_behavior_modulator\n",
      "\n",
      "Estou ótimo, obrigado! Fico feliz em saber que você está bem. Se houver algo em que eu possa ajudar ou se você quiser conversar sobre algum tópico específico, estou aqui para isso! 😊\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Oi, meu nome é Cristian\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
